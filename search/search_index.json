{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Homelab DevOps Overview","text":"<p> Golden Path \u2014 lint \u2192 plan \u2192 approve \u2192 apply \u2192 configure \u2192 monitor \u2192 smoke across AWS &amp; homelab (Proxmox/NFS). Built with Terraform \u00b7 Ansible \u00b7 Docker \u00b7 Prometheus \u00b7 Grafana \u00b7 GitHub Actions \u00b7 Jenkins \u00b7 MkDocs.</p> <p> </p>"},{"location":"#pipeline-at-a-glance","title":"Pipeline at a glance","text":"<pre><code>flowchart TD\n  A[Developer Laptop] --&gt;|Git Push| B[GitHub Actions / Jenkins]\n  B --&gt;|Static Checks| C[pre-commit \u00b7 TFLint \u00b7 Checkov \u00b7 Ansible-lint \u00b7 Hadolint]\n  B --&gt;|Plan| D[Terraform Plan]\n  D --&gt;|Manual Gate| E[Approve]\n  E --&gt;|Apply| F[Terraform Apply]\n  F --&gt;|Configure| G[Ansible Playbooks]\n  G --&gt;|Deploy/Proxy| H[Docker Reverse Proxy]\n  G --&gt;|Deploy Monitoring| M[Node Exporter]\n  F --&gt;|Alt Target| I[Proxmox VM + NFS]\n  G --&gt;|Smoke Tests| J[Health Checks]\n  M --&gt;|Metrics| K[Prometheus + Grafana]</code></pre>"},{"location":"#projects","title":"\ud83d\udcc1 Projects","text":"<ul> <li>\ud83c\udfd7\ufe0f Terraform Infrastructure - Multi-environment AWS provisioning with testing</li> <li>\ud83e\udd16 Ansible Automation - Configuration management with Vault secrets</li> <li>\u2638\ufe0f Kubernetes (K3s) - Production monitoring stack on K8s cluster</li> <li>\ud83d\udd04 GitOps (ArgoCD) - Declarative deployment with auto-sync and self-heal</li> <li>\ud83d\ude80 Jenkins CI/CD - Kubernetes-based with dynamic agent provisioning</li> <li>\ud83d\udce6 Packer Images - Automated AMI builds with security hardening</li> <li>\ud83d\udcca Monitoring Stack - Prometheus + Grafana + Loki + Tempo + AlertManager</li> <li>\ud83d\udcc8 Grafana Dashboards - 4 production dashboards auto-provisioned</li> <li>\ud83d\udd12 Security Scanning - Trivy container vulnerability scanning</li> <li>\ud83d\udc33 Docker / Reverse Proxy - Containerized services with Nginx</li> </ul>"},{"location":"#about-this-lab","title":"\ud83c\udfaf About This Lab","text":"<p>This homelab demonstrates production-ready DevOps practices:</p> <p>\u2705 Git-based workflows with CI/CD \u2705 Infrastructure as Code (Terraform with multi-environment) \u2705 Configuration management (Ansible with encrypted secrets) \u2705 Kubernetes orchestration (K3s with production workloads) \u2705 GitOps deployment (ArgoCD managing 2 applications) \u2705 CI/CD pipelines (Jenkins on K8s with dynamic agents) \u2705 Immutable infrastructure (Packer AMI builds with hardening) \u2705 Full observability stack (Metrics + Logs + Traces) \u2705 Production alerting with Slack integration \u2705 Container security scanning (Trivy in CI/CD) \u2705 Auto-provisioned Grafana dashboards (4 production-ready) \u2705 Centralized logging (Loki + Promtail, 30-day retention) \u2705 Distributed tracing (Tempo with trace correlation) \u2705 Docker containerization with reverse proxy \u2705 Security hardening (SSH, firewall, IDS, antivirus) \u2705 Automated testing &amp; validation \u2705 Disaster recovery (backup/restore automation)</p> <p>Goal: Operate like production infrastructure in a homelab, demonstrating enterprise-grade DevOps skills.</p>"},{"location":"#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"#monitoring-stack","title":"Monitoring Stack","text":"<pre><code># Start Prometheus + Grafana\nmake mon-up\n\n# Access Grafana at http://localhost:3001\n</code></pre>"},{"location":"#deploy-node-exporter-to-hosts","title":"Deploy Node Exporter to Hosts","text":"<pre><code>cd ansible\nansible-playbook playbooks/deploy-monitoring.yml\n</code></pre>"},{"location":"#provision-infrastructure","title":"Provision Infrastructure","text":"<pre><code>cd terraform/aws-ec2\nterraform init &amp;&amp; terraform plan\n</code></pre>"},{"location":"#tech-stack","title":"\ud83d\udee0\ufe0f Tech Stack","text":"Component Technology Infrastructure Terraform, AWS EC2, Proxmox Configuration Ansible, systemd Orchestration Kubernetes (K3s), Docker Compose GitOps ArgoCD (declarative deployment, auto-sync) CI/CD Jenkins (K8s dynamic agents), GitHub Actions Image Automation Packer (hardened AMI builds) Monitoring Prometheus, Grafana, AlertManager, Node Exporter, cAdvisor Logging Loki, Promtail Tracing Tempo (OTLP, trace correlation) Security Trivy, Ansible Vault, SELinux Containers Docker, Docker Compose CI/CD GitHub Actions, Jenkins, pre-commit Documentation MkDocs Material <p>Built by Stephon Skipper | Portfolio Site</p>"},{"location":"README-site-notes/","title":"Docs","text":"<p>Planned diagram of workflow (Terraform \u2192 Ansible \u2192 Docker \u2192 CI).</p>"},{"location":"ansible/","title":"Ansible Automation","text":"<p>My homelab uses Ansible to automatically configure and deploy workloads across:</p> <ul> <li>\ud83c\udfe0 Proxmox VMs (Docker nodes, NGINX proxy, Wazuh, PBS)</li> <li>\u2601\ufe0f AWS EC2 instances (created via Terraform)</li> <li>\ud83d\uddc3\ufe0f 45Drives NFS storage</li> <li>\ud83d\udd10 Security services (hardening, users, SSH, fail2ban)</li> <li>\ud83d\udce6 Application stack (Docker containers, monitoring, reverse proxy)</li> </ul> <p>This ensures consistent, repeatable infrastructure both at home and in the cloud.</p>"},{"location":"ansible/#end-to-end-automation-flow","title":"\ud83d\ude80 End-to-End Automation Flow","text":"<pre><code>flowchart LR\n  Git[Developer Commit] --&gt; CI[CI Pipeline: lint/validate/test]\n  CI --&gt; Terraform[Terraform Apply]\n  Terraform --&gt; Inventory[Generate Dynamic Inventory]\n  Inventory --&gt; Ansible[Run Ansible Playbooks]\n  Ansible --&gt; Deploy[Deploy Apps &amp; Config]\n  Deploy --&gt; Health[Smoke Tests / Health Checks]</code></pre>"},{"location":"ansible/#example-inventory","title":"\ud83d\udccb Example Inventory","text":"<pre><code>[proxmox]\ndockenode1 ansible_host=192.168.1.201\ndockenode2 ansible_host=192.168.1.202\nwazuh ansible_host=192.168.1.203\nproxy ansible_host=192.168.1.204\npbs ansible_host=192.168.1.205\n\n[aws]\naws-prod ansible_host=54.123.45.67\n</code></pre>"},{"location":"ansible/#example-playbook","title":"\ud83d\udcdd Example Playbook","text":"<pre><code>- name: Base configuration\n  hosts: all\n  become: yes\n\n  roles:\n    - common      # users, system settings\n    - security    # firewall, fail2ban, ssh hardening\n    - docker      # docker + compose install\n</code></pre>"},{"location":"ansible/#ansible-execution-screenshot","title":"\u2705 Ansible Execution Screenshot","text":"<p>Below is a real run of my Ansible playbook against my homelab VMs:</p> <p></p>"},{"location":"ansible/#ansible-workflow-diagram","title":"\ud83d\udd27 Ansible Workflow Diagram","text":"<pre><code>flowchart LR\n  GH[Git Push to GitHub] --&gt; CI[CI Pipeline]\n  CI --&gt; Lint[Lint + Security Scan]\n  CI --&gt; Deploy[Run Ansible Playbook]\n  Deploy --&gt; Proxmox[Configure Proxmox VMs]\n  Deploy --&gt; AWS[Configure AWS EC2 Instance]\n  Proxmox --&gt; Services[Deploy Homelab Services]\n  AWS --&gt; Services\n  Services --&gt; Smoke[Smoke Tests / Health Checks]</code></pre>"},{"location":"ansible/#example-inventory-production","title":"\ud83d\udccb Example Inventory (Production)","text":"<pre><code>[proxmox]\n192.xxx.x.xxx\n192.xxx.x.xxx\n\n[aws]\n3.89.xx.xx\n</code></pre>"},{"location":"ansible/#demo-playbook-example","title":"\ud83d\udcdd Demo Playbook Example","text":"<pre><code>- name: Homelab Automation Demo\n  hosts: all\n  become: true\n\n  tasks:\n    - name: Ping test\n      ping:\n\n    - name: Ensure NGINX installed (example)\n      apt:\n        name: nginx\n        state: present\n      when: ansible_os_family == \"Debian\"\n</code></pre>"},{"location":"ansible/#monitoring-role","title":"\ud83d\udcca Monitoring Role","text":"<p>Automates deployment of Prometheus Node Exporter to infrastructure for metrics collection.</p>"},{"location":"ansible/#features","title":"Features","text":"<ul> <li>\u2705 Installs Node Exporter as systemd service</li> <li>\u2705 Automatic firewall configuration</li> <li>\u2705 Security hardening (unprivileged user, systemd protections)</li> <li>\u2705 Version management &amp; idempotent updates</li> <li>\u2705 Health check verification</li> </ul>"},{"location":"ansible/#quick-deploy","title":"Quick Deploy","text":"<pre><code># Deploy to all hosts\ncd ansible\nansible-playbook playbooks/deploy-monitoring.yml\n\n# Deploy to specific group\nansible-playbook playbooks/deploy-monitoring.yml --limit monitoring\n\n# Verify installation\nansible all -m uri -a \"url=http://localhost:9100/metrics status_code=200\"\n</code></pre>"},{"location":"ansible/#integration-with-prometheus","title":"Integration with Prometheus","text":"<p>After deployment, add hosts to <code>docker/monitoring-stack/prometheus/prometheus.yml</code>:</p> <pre><code>scrape_configs:\n  - job_name: 'node_exporter_homelab'\n    static_configs:\n      - targets:\n          - 'server1.local:9100'\n          - 'server2.local:9100'\n          - 'server3.local:9100'\n        labels:\n          environment: 'homelab'\n</code></pre> <p>See the monitoring role on GitHub for complete documentation.</p>"},{"location":"ansible/#security-role","title":"\ud83d\udd10 Security Role","text":"<p>Coming soon: Automated security hardening, SSH configuration, and fail2ban setup.</p>"},{"location":"architecture/","title":"Architecture","text":"<pre><code>flowchart LR\n  Dev[Developer] --&gt;|Git push| CI[GitHub Actions/Jenkins]\n  CI --&gt; Lint[pre-commit TFLint Checkov Hadolint ansible-lint]\n  CI --&gt; Plan[Terraform Plan] --&gt; Gate[Manual Approve] --&gt; Apply[Terraform Apply]\n  Apply --&gt; AWS[AWS EC2]\n  Apply --&gt; Proxmox[Proxmox VM]\n  Proxmox --&gt; NFS[45Drives NFS]\n  AWS --&gt; Ansible[Ansible Configure]\n  Proxmox --&gt; Ansible\n  Ansible --&gt; Proxy[Reverse Proxy Docker]\n  Proxy --&gt; Smoke[Health/Smoke]</code></pre>"},{"location":"architecture/#proxmox-virtualization-layer","title":"Proxmox Virtualization Layer","text":"<p>This node runs my core homelab workloads: Docker nodes, Nginx reverse proxy, Wazuh, an Ubuntu admin VM, NFS mount (45Drives), and Proxmox Backup Server (PBS).</p>"},{"location":"docker/","title":"Docker &amp; Containerization","text":"<p>This homelab uses Docker and Docker Compose for containerized service orchestration.</p>"},{"location":"docker/#monitoring-stack","title":"\ud83d\udc33 Monitoring Stack","text":"<p>The primary Docker deployment is the full observability stack running in <code>docker/monitoring-stack/</code>:</p>"},{"location":"docker/#services","title":"Services","text":"Service Image Port Purpose Prometheus <code>prom/prometheus:latest</code> 9090 Metrics collection &amp; storage (15-day retention) Grafana <code>grafana/grafana:latest</code> 3001 Visualization &amp; dashboards AlertManager <code>prom/alertmanager:latest</code> 9093 Alert routing &amp; notification Loki <code>grafana/loki:latest</code> 3100 Log aggregation &amp; storage (30-day retention) Promtail <code>grafana/promtail:latest</code> - Log collection from Docker containers Tempo <code>grafana/tempo:latest</code> 3200 Distributed tracing (30-day retention) Node Exporter <code>prom/node-exporter:latest</code> 9100 Host system metrics cAdvisor <code>gcr.io/cadvisor/cadvisor:latest</code> 8080 Container metrics"},{"location":"docker/#quick-start","title":"Quick Start","text":"<pre><code># Start the entire monitoring stack\nmake mon-up\n\n# View logs\nmake mon-logs\n\n# Stop the stack\nmake mon-down\n\n# Restart a specific service\ndocker compose -f docker/monitoring-stack/docker-compose.yml restart grafana\n</code></pre>"},{"location":"docker/#access-points","title":"Access Points","text":"<ul> <li>Grafana: http://localhost:3001 (admin / changeme-please)</li> <li>Prometheus: http://localhost:9090</li> <li>AlertManager: http://localhost:9093</li> <li>Loki: http://localhost:3100</li> <li>Tempo: http://localhost:3200</li> <li>cAdvisor: http://localhost:8080</li> </ul>"},{"location":"docker/#stack-structure","title":"\ud83d\udcc1 Stack Structure","text":"<pre><code>docker/monitoring-stack/\n\u251c\u2500\u2500 docker-compose.yml              # Service orchestration\n\u251c\u2500\u2500 prometheus/\n\u2502   \u251c\u2500\u2500 prometheus.yml              # Scrape configs\n\u2502   \u2514\u2500\u2500 rules/                      # Alert rules\n\u2502       \u251c\u2500\u2500 node_alerts.yml\n\u2502       \u251c\u2500\u2500 container_alerts.yml\n\u2502       \u2514\u2500\u2500 service_alerts.yml\n\u251c\u2500\u2500 alertmanager/\n\u2502   \u2514\u2500\u2500 alertmanager.yml            # Slack integration\n\u251c\u2500\u2500 grafana/\n\u2502   \u2514\u2500\u2500 provisioning/\n\u2502       \u251c\u2500\u2500 datasources/            # Auto-provisioned datasources\n\u2502       \u2502   \u251c\u2500\u2500 prometheus.yml\n\u2502       \u2502   \u251c\u2500\u2500 loki.yml\n\u2502       \u2502   \u2514\u2500\u2500 tempo.yml\n\u2502       \u2514\u2500\u2500 dashboards/             # Auto-provisioned dashboards\n\u2502           \u251c\u2500\u2500 dashboards.yml\n\u2502           \u2514\u2500\u2500 json/\n\u2502               \u251c\u2500\u2500 dashboard-1860.json    # Node Exporter Full\n\u2502               \u251c\u2500\u2500 dashboard-179.json     # Docker &amp; System\n\u2502               \u251c\u2500\u2500 dashboard-893.json     # cAdvisor\n\u2502               \u2514\u2500\u2500 dashboard-15172.json   # Node Quickstart\n\u251c\u2500\u2500 loki/\n\u2502   \u2514\u2500\u2500 loki-config.yaml            # Log storage config\n\u251c\u2500\u2500 promtail/\n\u2502   \u2514\u2500\u2500 promtail-config.yaml        # Log collection config\n\u2514\u2500\u2500 tempo/\n    \u2514\u2500\u2500 tempo-config.yaml           # Trace storage config\n</code></pre>"},{"location":"docker/#configuration-highlights","title":"\ud83d\udd27 Configuration Highlights","text":""},{"location":"docker/#prometheus","title":"Prometheus","text":"<ul> <li>Retention: 15 days</li> <li>Scrape Interval: 15 seconds</li> <li>Targets: Node Exporter, cAdvisor, Prometheus self-monitoring</li> <li>Alert Rules: CPU, memory, disk, service availability</li> <li>Remote Write: Tempo metrics generator</li> </ul>"},{"location":"docker/#loki","title":"Loki","text":"<ul> <li>Retention: 30 days (720 hours)</li> <li>Storage: Local filesystem with compaction</li> <li>Schema: TSDB with v13 schema</li> <li>Log Sources: Docker containers (via Promtail)</li> </ul>"},{"location":"docker/#tempo","title":"Tempo","text":"<ul> <li>Retention: 30 days (720 hours)</li> <li>Receivers: OTLP gRPC (4317), OTLP HTTP (4318)</li> <li>Storage: Local filesystem</li> <li>Features: Service graphs, span metrics, trace correlation</li> </ul>"},{"location":"docker/#grafana","title":"Grafana","text":"<ul> <li>Datasources: Auto-provisioned (Prometheus, Loki, Tempo)</li> <li>Dashboards: 4 pre-built dashboards auto-imported</li> <li>Theme: Dark mode by default</li> <li>Features: Explore, Alerting, Unified Search</li> </ul>"},{"location":"docker/#deployment-best-practices","title":"\ud83d\ude80 Deployment Best Practices","text":""},{"location":"docker/#environment-variables","title":"Environment Variables","text":"<p>Create <code>.env</code> file in <code>docker/monitoring-stack/</code>:</p> <pre><code>GRAFANA_PORT=3001\nPROMETHEUS_PORT=9090\nALERTMANAGER_PORT=9093\nLOKI_PORT=3100\nTEMPO_PORT=3200\nCADVISOR_PORT=8080\n\nGF_SECURITY_ADMIN_USER=admin\nGF_SECURITY_ADMIN_PASSWORD=your-secure-password-here\n</code></pre>"},{"location":"docker/#volume-management","title":"Volume Management","text":"<p>All data is persisted in Docker volumes:</p> <pre><code># List monitoring volumes\ndocker volume ls | grep monitoring-stack\n\n# Backup Grafana data\ndocker run --rm -v monitoring-stack_grafana_data:/data \\\n  -v $(pwd)/backups:/backup ubuntu tar czf /backup/grafana-$(date +%F).tar.gz /data\n\n# Restore Grafana data\ndocker run --rm -v monitoring-stack_grafana_data:/data \\\n  -v $(pwd)/backups:/backup ubuntu tar xzf /backup/grafana-2024-11-02.tar.gz -C /\n</code></pre>"},{"location":"docker/#health-checks","title":"Health Checks","text":"<p>Verify all services are healthy:</p> <pre><code># Check container status\ndocker ps --filter \"name=mon-\" --format \"table {{.Names}}\\t{{.Status}}\"\n\n# Test endpoints\ncurl -s http://localhost:9090/-/healthy &amp;&amp; echo \" \u2713 Prometheus\"\ncurl -s http://localhost:3001/api/health &amp;&amp; echo \" \u2713 Grafana\"\ncurl -s http://localhost:3100/ready &amp;&amp; echo \" \u2713 Loki\"\ncurl -s http://localhost:3200/ready &amp;&amp; echo \" \u2713 Tempo\"\n</code></pre>"},{"location":"docker/#security-considerations","title":"\ud83d\udd12 Security Considerations","text":""},{"location":"docker/#network-isolation","title":"Network Isolation","text":"<ul> <li>Services communicate via internal <code>monitoring</code> network</li> <li>Only necessary ports exposed to host</li> <li>No external internet access required for core functionality</li> </ul>"},{"location":"docker/#secrets-management","title":"Secrets Management","text":"<ul> <li>Grafana admin credentials in <code>.env</code> file (gitignored)</li> <li>AlertManager Slack webhook in <code>alertmanager.yml</code> (can use Ansible Vault)</li> <li>Use strong passwords in production</li> </ul>"},{"location":"docker/#selinux-compatibility","title":"SELinux Compatibility","text":"<p>All volume mounts use <code>:z</code> flag for SELinux compatibility on Fedora/RHEL:</p> <pre><code>volumes:\n  - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro,z\n</code></pre>"},{"location":"docker/#observability-features","title":"\ud83d\udcca Observability Features","text":""},{"location":"docker/#unified-correlation","title":"Unified Correlation","text":"<p>The stack provides 3 pillars of observability with full correlation:</p> <ol> <li>Metrics (Prometheus) \u2192 View in Grafana dashboards</li> <li>Logs (Loki) \u2192 Click trace ID in logs \u2192 Jump to Tempo</li> <li>Traces (Tempo) \u2192 Click log link in trace \u2192 Jump to Loki</li> </ol>"},{"location":"docker/#example-workflow","title":"Example Workflow","text":"<ol> <li>Alert fires \u2192 AlertManager sends Slack notification</li> <li>View dashboard \u2192 Grafana shows metric spike</li> <li>Check logs \u2192 Loki shows error messages with trace IDs</li> <li>Trace request \u2192 Tempo shows distributed trace across services</li> <li>Correlate \u2192 Jump between metrics/logs/traces seamlessly</li> </ol>"},{"location":"docker/#troubleshooting","title":"\ud83d\udee0\ufe0f Troubleshooting","text":""},{"location":"docker/#service-wont-start","title":"Service Won't Start","text":"<pre><code># Check logs\ndocker logs mon-&lt;service-name&gt;\n\n# Common issues:\n# 1. Port already in use\nsudo lsof -i :9090  # Check if port is taken\n\n# 2. Permission denied (SELinux)\nsudo ausearch -m avc -ts recent  # Check SELinux denials\n\n# 3. Config syntax error\ndocker compose -f docker/monitoring-stack/docker-compose.yml config\n</code></pre>"},{"location":"docker/#grafana-cant-connect-to-datasources","title":"Grafana Can't Connect to Datasources","text":"<pre><code># Check network connectivity\ndocker exec mon-grafana ping -c 2 prometheus\ndocker exec mon-grafana ping -c 2 loki\ndocker exec mon-grafana ping -c 2 tempo\n\n# Verify datasource configs\nls -la docker/monitoring-stack/grafana/provisioning/datasources/\n</code></pre>"},{"location":"docker/#high-memory-usage","title":"High Memory Usage","text":"<pre><code># Check resource usage\ndocker stats --no-stream\n\n# Reduce retention periods in configs:\n# - Prometheus: storage.tsdb.retention.time\n# - Loki: limits_config.retention_period\n# - Tempo: compactor.compaction.block_retention\n</code></pre>"},{"location":"docker/#additional-resources","title":"\ud83d\udcda Additional Resources","text":"<ul> <li>Prometheus Documentation</li> <li>Grafana Documentation</li> <li>Loki Documentation</li> <li>Tempo Documentation</li> <li>Docker Compose Documentation</li> </ul>"},{"location":"docker/#related-pages","title":"\ud83d\udd17 Related Pages","text":"<ul> <li>Monitoring &amp; Observability - Alert rules and runbooks</li> <li>Grafana Dashboards - Dashboard details and customization</li> <li>Security Scanning - Trivy container vulnerability scanning</li> <li>Architecture - System architecture diagrams</li> </ul>"},{"location":"gitops/","title":"GitOps with ArgoCD","text":"<p>This guide demonstrates the implementation of GitOps methodology using ArgoCD for declarative, continuous deployment to our K3s Kubernetes cluster.</p>"},{"location":"gitops/#what-is-gitops","title":"\ud83c\udfaf What is GitOps?","text":"<p>GitOps is a modern approach to continuous deployment where:</p> <ul> <li>Git is the single source of truth for declarative infrastructure and applications</li> <li>Automated processes sync desired state from Git to production</li> <li>Continuous reconciliation ensures cluster state matches Git state</li> <li>Complete audit trail via Git history of all changes</li> <li>Easy rollbacks through Git revert operations</li> </ul>"},{"location":"gitops/#architecture","title":"\ud83c\udfd7\ufe0f Architecture","text":"<pre><code>graph TB\n    subgraph Developer Workflow\n        DEV[Developer]\n        IDE[Code Editor]\n        GIT[Git Repository&lt;br/&gt;github.com/iso-st3ph/homelab-devops]\n    end\n\n    subgraph ArgoCD Platform\n        ARGO[ArgoCD&lt;br/&gt;Controller]\n        UI[ArgoCD UI&lt;br/&gt;:30443]\n        REPO[Repo Server]\n    end\n\n    subgraph K3s Cluster\n        subgraph Monitoring Namespace\n            PROM[Prometheus]\n            GRAF[Grafana]\n            LOKI[Loki]\n            TEMPO[Tempo]\n            ALERT[AlertManager]\n        end\n    end\n\n    DEV --&gt;|1. Edit Manifests| IDE\n    IDE --&gt;|2. Commit &amp; Push| GIT\n    GIT --&gt;|3. Webhook/Poll| ARGO\n    ARGO --&gt;|4. Sync| REPO\n    REPO --&gt;|5. Apply| PROM\n    REPO --&gt;|5. Apply| GRAF\n    REPO --&gt;|5. Apply| LOKI\n    REPO --&gt;|5. Apply| TEMPO\n    REPO --&gt;|5. Apply| ALERT\n    PROM -.-&gt;|6. Report Status| ARGO\n    GRAF -.-&gt;|6. Report Status| ARGO\n    ARGO &lt;--&gt;|7. View/Manage| UI</code></pre>"},{"location":"gitops/#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"gitops/#access-argocd-ui","title":"Access ArgoCD UI","text":"<pre><code># Get admin password\nkubectl get secret argocd-initial-admin-secret -n argocd \\\n  -o jsonpath=\"{.data.password}\" | base64 -d &amp;&amp; echo\n\n# Or use Makefile\nmake argocd-ui\n\n# Access UI\n# URL: https://localhost:30443\n# Username: admin\n</code></pre>"},{"location":"gitops/#deploy-application","title":"Deploy Application","text":"<pre><code># Apply AppProject and Application\nmake argocd-apps\n\n# Check status\nmake argocd-status\n</code></pre>"},{"location":"gitops/#current-applications","title":"\ud83d\udce6 Current Applications","text":""},{"location":"gitops/#monitoring-stack","title":"Monitoring Stack","text":"<p>Repository: <code>https://github.com/iso-st3ph/homelab-devops.git</code> Path: <code>kubernetes/monitoring/</code> Namespace: <code>monitoring</code></p> <p>Services Deployed:</p> <ul> <li>Prometheus - Metrics collection and storage</li> <li>Grafana - Visualization and dashboards</li> <li>Loki - Log aggregation</li> <li>Tempo - Distributed tracing</li> <li>AlertManager - Alert routing and notification</li> </ul> <p>Sync Policy:</p> <pre><code>syncPolicy:\n  automated:\n    prune: true       # Remove resources deleted from Git\n    selfHeal: true    # Auto-correct drift\n    allowEmpty: false\n  syncOptions:\n    - CreateNamespace=true\n  retry:\n    limit: 5\n    backoff:\n      duration: 5s\n      factor: 2\n      maxDuration: 3m\n</code></pre>"},{"location":"gitops/#gitops-workflow","title":"\ud83d\udd04 GitOps Workflow","text":""},{"location":"gitops/#making-changes","title":"Making Changes","text":"<ol> <li>Edit Manifests Locally</li> </ol> <pre><code>cd kubernetes/monitoring/\n# Edit deployment, configmap, etc.\nvim 03-prometheus.yaml\n</code></pre> <ol> <li>Commit Changes</li> </ol> <pre><code>git add kubernetes/monitoring/\ngit commit -m \"feat(monitoring): increase Prometheus retention to 30 days\"\n</code></pre> <ol> <li>Push to GitHub</li> </ol> <pre><code>git push origin main\n</code></pre> <ol> <li>ArgoCD Auto-Sync (within 3 minutes)</li> <li>ArgoCD detects changes in Git</li> <li>Compares desired state (Git) vs actual state (cluster)</li> <li>Applies differences to cluster</li> <li>Reports health status</li> </ol>"},{"location":"gitops/#manual-sync","title":"Manual Sync","text":"<pre><code># Trigger immediate sync\nmake argocd-sync\n\n# Or via kubectl\nkubectl patch application monitoring-stack -n argocd \\\n  --type merge -p '{\"operation\":{\"initiatedBy\":{\"username\":\"admin\"},\"sync\":{}}}'\n</code></pre>"},{"location":"gitops/#rollback","title":"Rollback","text":"<pre><code># Revert Git commit\ngit revert HEAD\ngit push origin main\n\n# ArgoCD auto-syncs rollback within 3 minutes\n# Or manually sync for immediate rollback\nmake argocd-sync\n</code></pre>"},{"location":"gitops/#monitoring-status","title":"\ud83d\udcca Monitoring &amp; Status","text":""},{"location":"gitops/#application-health","title":"Application Health","text":"<pre><code># Get sync and health status\nkubectl get application monitoring-stack -n argocd\n\n# Detailed status\nkubectl describe application monitoring-stack -n argocd\n</code></pre> <p>Health Status Meanings:</p> <ul> <li>Healthy: All resources running as expected</li> <li>Progressing: Resources being created/updated</li> <li>Degraded: Some resources failing</li> <li>Missing: Resources not found in cluster</li> </ul> <p>Sync Status:</p> <ul> <li>Synced: Cluster state matches Git state</li> <li>OutOfSync: Cluster differs from Git</li> <li>Unknown: Unable to determine sync status</li> </ul>"},{"location":"gitops/#resource-status","title":"Resource Status","text":"<pre><code># View managed resources\nkubectl get application monitoring-stack -n argocd \\\n  -o jsonpath='{.status.resources[*].name}' | tr ' ' '\\n'\n\n# Resource health details\nkubectl get application monitoring-stack -n argocd \\\n  -o jsonpath='{.status.resources[*].health.status}'\n</code></pre>"},{"location":"gitops/#sync-history","title":"Sync History","text":"<pre><code># View sync history in UI\n# Navigate to: Applications \u2192 monitoring-stack \u2192 History\n\n# Via CLI\nkubectl get application monitoring-stack -n argocd \\\n  -o jsonpath='{.status.history}'\n</code></pre>"},{"location":"gitops/#advanced-features","title":"\ud83c\udf9b\ufe0f Advanced Features","text":""},{"location":"gitops/#sync-waves","title":"Sync Waves","text":"<p>Control deployment order with annotations:</p> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: app-config\n  annotations:\n    argocd.argoproj.io/sync-wave: \"0\"  # Deploy first\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app\n  annotations:\n    argocd.argoproj.io/sync-wave: \"1\"  # Deploy after configmaps\n</code></pre> <p>Common Wave Strategy:</p> <ul> <li>Wave -1: Namespace creation</li> <li>Wave 0: ConfigMaps, Secrets</li> <li>Wave 1: PVCs, Services</li> <li>Wave 2: Deployments, StatefulSets</li> <li>Wave 3: Ingress, Routes</li> </ul>"},{"location":"gitops/#resource-hooks","title":"Resource Hooks","text":"<p>Run jobs at specific sync phases:</p> <pre><code>apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: database-migration\n  annotations:\n    argocd.argoproj.io/hook: PreSync\n    argocd.argoproj.io/hook-delete-policy: HookSucceeded\nspec:\n  template:\n    spec:\n      containers:\n        - name: migrate\n          image: my-app:latest\n          command: [\"./migrate.sh\"]\n</code></pre> <p>Hook Types:</p> <ul> <li><code>PreSync</code>: Before sync</li> <li><code>Sync</code>: During sync</li> <li><code>PostSync</code>: After sync</li> <li><code>SyncFail</code>: On sync failure</li> <li><code>Skip</code>: Skip resource in sync</li> </ul>"},{"location":"gitops/#ignore-differences","title":"Ignore Differences","text":"<p>Prevent sync on specific fields:</p> <pre><code>ignoreDifferences:\n  - group: apps\n    kind: Deployment\n    jsonPointers:\n      - /spec/replicas  # Ignore replica count (for HPA)\n  - group: apps\n    kind: StatefulSet\n    jsonPointers:\n      - /spec/volumeClaimTemplates  # Ignore PVC changes\n</code></pre>"},{"location":"gitops/#security-rbac","title":"\ud83d\udd10 Security &amp; RBAC","text":""},{"location":"gitops/#appprojects","title":"AppProjects","text":"<p>Our <code>homelab</code> AppProject provides:</p> <p>Repository Access:</p> <pre><code>sourceRepos:\n  - https://github.com/iso-st3ph/homelab-devops.git\n</code></pre> <p>Destination Control:</p> <pre><code>destinations:\n  - namespace: '*'\n    server: https://kubernetes.default.svc\n</code></pre> <p>RBAC Roles:</p> <ul> <li>Admin: Full application management</li> <li>Developer: Read and sync only</li> </ul>"},{"location":"gitops/#authentication","title":"Authentication","text":"<p>ArgoCD supports multiple auth methods:</p> <ul> <li>Local users (current: admin)</li> <li>SSO (OIDC, SAML, LDAP)</li> <li>API tokens for CI/CD integration</li> </ul>"},{"location":"gitops/#secrets-management","title":"Secrets Management","text":"<p>Current Approach: Secrets in Kubernetes</p> <pre><code># Example: Create secret for Grafana\nkubectl create secret generic grafana-admin \\\n  --from-literal=password='secure-password' \\\n  -n monitoring\n</code></pre> <p>Best Practices:</p> <ul> <li>Use Sealed Secrets or External Secrets Operator</li> <li>Reference secrets in manifests, don't commit plaintext</li> <li>Rotate credentials regularly</li> </ul>"},{"location":"gitops/#multi-environment-strategy","title":"\ud83d\udcc8 Multi-Environment Strategy","text":""},{"location":"gitops/#using-git-branches","title":"Using Git Branches","text":"<pre><code>main \u2192 production (auto-sync enabled)\nstaging \u2192 staging namespace (auto-sync enabled)\ndevelop \u2192 development namespace (manual sync)\n</code></pre>"},{"location":"gitops/#using-kustomize-overlays","title":"Using Kustomize Overlays","text":"<pre><code>kubernetes/\n\u251c\u2500\u2500 base/\n\u2502   \u251c\u2500\u2500 deployment.yaml\n\u2502   \u2514\u2500\u2500 kustomization.yaml\n\u2514\u2500\u2500 overlays/\n    \u251c\u2500\u2500 dev/\n    \u2502   \u2514\u2500\u2500 kustomization.yaml\n    \u251c\u2500\u2500 staging/\n    \u2502   \u2514\u2500\u2500 kustomization.yaml\n    \u2514\u2500\u2500 prod/\n        \u2514\u2500\u2500 kustomization.yaml\n</code></pre>"},{"location":"gitops/#applicationset-pattern","title":"ApplicationSet Pattern","text":"<pre><code>apiVersion: argoproj.io/v1alpha1\nkind: ApplicationSet\nmetadata:\n  name: monitoring-multi-env\nspec:\n  generators:\n    - list:\n        elements:\n          - env: dev\n            replicas: 1\n          - env: prod\n            replicas: 3\n  template:\n    spec:\n      source:\n        path: kubernetes/monitoring\n        helm:\n          parameters:\n            - name: replicas\n              value: '{{replicas}}'\n</code></pre>"},{"location":"gitops/#troubleshooting","title":"\ud83d\udee0\ufe0f Troubleshooting","text":""},{"location":"gitops/#application-not-syncing","title":"Application Not Syncing","text":"<p>Check sync settings:</p> <pre><code>kubectl get application monitoring-stack -n argocd -o yaml | grep -A 10 syncPolicy\n</code></pre> <p>Manual refresh:</p> <pre><code>kubectl patch application monitoring-stack -n argocd \\\n  --type merge -p '{\"metadata\":{\"annotations\":{\"argocd.argoproj.io/refresh\":\"normal\"}}}'\n</code></pre>"},{"location":"gitops/#resources-stuck-in-progressing","title":"Resources Stuck in Progressing","text":"<p>Check pod status:</p> <pre><code>kubectl get pods -n monitoring\nkubectl describe pod &lt;pod-name&gt; -n monitoring\n</code></pre> <p>View ArgoCD logs:</p> <pre><code>kubectl logs -n argocd -l app.kubernetes.io/name=argocd-application-controller\n</code></pre>"},{"location":"gitops/#sync-fails","title":"Sync Fails","text":"<p>View sync operation:</p> <pre><code>kubectl get application monitoring-stack -n argocd -o yaml | grep -A 20 operation\n</code></pre> <p>Check for validation errors:</p> <pre><code>kubectl describe application monitoring-stack -n argocd | grep -A 20 Conditions\n</code></pre>"},{"location":"gitops/#best-practices","title":"\ud83c\udfaf Best Practices","text":""},{"location":"gitops/#do","title":"\u2705 Do","text":"<ul> <li>Commit all manifests to Git - Git is source of truth</li> <li>Use meaningful commit messages - They become deployment history</li> <li>Enable auto-sync for production - Reduce manual intervention</li> <li>Use sync waves - Control deployment order</li> <li>Implement health checks - Ensure reliable deployments</li> <li>Monitor sync status - Set up alerts for failed syncs</li> <li>Use AppProjects - Isolate teams and environments</li> </ul>"},{"location":"gitops/#dont","title":"\u274c Don't","text":"<ul> <li>Don't kubectl apply manually - Bypasses GitOps</li> <li>Don't edit resources in cluster - Changes will be overwritten</li> <li>Don't disable self-heal - Defeats purpose of GitOps</li> <li>Don't commit secrets - Use secret management tools</li> <li>Don't ignore sync errors - Fix root cause, don't retry blindly</li> </ul>"},{"location":"gitops/#integration-examples","title":"\ud83d\udcda Integration Examples","text":""},{"location":"gitops/#cicd-pipeline-integration","title":"CI/CD Pipeline Integration","text":"<pre><code># GitHub Actions\n- name: Update Deployment Image\n  run: |\n    yq eval '.spec.template.spec.containers[0].image = \"${{ env.IMAGE }}\"' \\\n      -i kubernetes/monitoring/03-prometheus.yaml\n    git commit -am \"chore: update Prometheus image to ${{ env.IMAGE }}\"\n    git push\n    # ArgoCD auto-syncs new image within 3 minutes\n</code></pre>"},{"location":"gitops/#notification-webhooks","title":"Notification Webhooks","text":"<p>Configure Slack/email notifications:</p> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: argocd-notifications-cm\ndata:\n  service.slack: |\n    token: $slack-token\n  trigger.on-sync-succeeded: |\n    - send: [app-deployed]\n</code></pre>"},{"location":"gitops/#skills-demonstrated","title":"\ud83c\udf93 Skills Demonstrated","text":"<p>This GitOps implementation showcases:</p> <ul> <li>\u2705 GitOps Methodology - Declarative, Git-based deployments</li> <li>\u2705 Continuous Deployment - Automated sync from Git to cluster</li> <li>\u2705 Self-Healing Infrastructure - Automatic drift correction</li> <li>\u2705 Declarative Management - Desired state in version control</li> <li>\u2705 RBAC &amp; Security - Role-based access with AppProjects</li> <li>\u2705 Audit &amp; Compliance - Complete change history in Git</li> <li>\u2705 Production Patterns - Sync waves, hooks, multi-environment</li> <li>\u2705 Disaster Recovery - Git-based rollback capability</li> </ul>"},{"location":"gitops/#references","title":"\ud83d\udcd6 References","text":"<ul> <li>ArgoCD Documentation</li> <li>GitOps Principles</li> <li>ArgoCD Best Practices</li> <li>CNCF GitOps Working Group</li> </ul> <p>Built by Stephon Skipper | GitHub</p>"},{"location":"grafana-dashboards/","title":"Grafana Dashboards","text":"<p>This project includes 4 pre-built production dashboards automatically provisioned from Grafana.com. These dashboards provide comprehensive visibility into system metrics, container performance, and infrastructure health.</p>"},{"location":"grafana-dashboards/#available-dashboards","title":"\ud83d\udcca Available Dashboards","text":""},{"location":"grafana-dashboards/#1-node-exporter-full-id-1860","title":"1. Node Exporter Full (ID: 1860)","text":"<p>Purpose: Complete system monitoring for Linux servers Metrics Covered: - CPU usage (user, system, iowait, steal) - Memory utilization (used, cached, buffered, swap) - Disk I/O (read/write throughput, IOPS) - Network traffic (bandwidth, errors, drops) - Filesystem usage (disk space, inodes) - System load averages (1min, 5min, 15min)</p> <p>Use Cases: - Capacity planning and trend analysis - Performance troubleshooting - Resource optimization - SLA monitoring</p> <p>Visualization Highlights: - Time-series graphs with zoom/pan - Heatmaps for latency distribution - Gauge panels for current utilization - Table view for multi-server comparison</p>"},{"location":"grafana-dashboards/#2-docker-system-monitoring-id-179","title":"2. Docker &amp; System Monitoring (ID: 179)","text":"<p>Purpose: Docker container and host system overview Metrics Covered: - Container count (running/stopped/paused) - CPU usage per container - Memory consumption per container - Network I/O per container - Block I/O per container - Host system metrics</p> <p>Use Cases: - Container resource allocation - Troubleshooting container performance issues - Identifying resource-hungry containers - Planning container migrations</p> <p>Visualization Highlights: - Single-pane view of all containers - Color-coded status indicators - Sortable container tables - Host vs. container resource split</p>"},{"location":"grafana-dashboards/#3-cadvisor-prometheus-id-893","title":"3. cAdvisor Prometheus (ID: 893)","text":"<p>Purpose: Detailed container metrics from cAdvisor Metrics Covered: - Per-container CPU throttling - Memory working set and RSS - Filesystem usage by container - Network bandwidth per interface - Container restart counts - OOM kill events</p> <p>Use Cases: - Deep-dive container diagnostics - Memory leak detection - CPU throttling analysis - Network bottleneck identification</p> <p>Visualization Highlights: - Container-level drill-down - Multi-axis graphs (CPU + memory) - Alert annotation overlays - Historical trend comparison</p>"},{"location":"grafana-dashboards/#4-node-exporter-quickstart-id-15172","title":"4. Node Exporter Quickstart (ID: 15172)","text":"<p>Purpose: Simplified node metrics dashboard Metrics Covered: - Essential CPU, memory, disk metrics - Quick health status overview - Key performance indicators (KPIs) - Top processes by resource usage</p> <p>Use Cases: - At-a-glance system health checks - Executive/manager-friendly views - Lightweight alternative to Full dashboard - Mobile-friendly layout</p> <p>Visualization Highlights: - Large stat panels for quick reading - Green/yellow/red color coding - Minimal clutter, maximum clarity - Auto-refresh every 30 seconds</p>"},{"location":"grafana-dashboards/#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"grafana-dashboards/#import-dashboards","title":"Import Dashboards","text":"<p>Run the automated import script:</p> <pre><code># Import all 4 dashboards\nmake grafana-dashboards\n\n# Or manually:\n./scripts/import-grafana-dashboards.sh\n</code></pre> <p>What it does: 1. Downloads dashboard JSON from Grafana.com 2. Configures datasources to use local Prometheus 3. Creates dashboard provider configuration 4. Saves dashboards to <code>docker/monitoring-stack/grafana/provisioning/dashboards/json/</code></p>"},{"location":"grafana-dashboards/#restart-grafana","title":"Restart Grafana","text":"<pre><code># Restart Grafana container to load new dashboards\ndocker compose -f docker/monitoring-stack/docker-compose.yml restart grafana\n\n# Or restart entire monitoring stack\nmake mon-down &amp;&amp; make mon-up\n</code></pre>"},{"location":"grafana-dashboards/#access-dashboards","title":"Access Dashboards","text":"<ol> <li>Open Grafana: http://localhost:3000</li> <li>Login (default: <code>admin</code> / <code>changeme-please</code>)</li> <li>Navigate: Dashboards \u2192 Browse \u2192 Imported folder</li> <li>Select any dashboard to view</li> </ol>"},{"location":"grafana-dashboards/#file-structure","title":"\ud83d\udcc1 File Structure","text":"<pre><code>docker/monitoring-stack/grafana/\n\u251c\u2500\u2500 provisioning/\n\u2502   \u251c\u2500\u2500 dashboards/\n\u2502   \u2502   \u251c\u2500\u2500 dashboards.yml          # Auto-provisioning config\n\u2502   \u2502   \u2514\u2500\u2500 json/\n\u2502   \u2502       \u251c\u2500\u2500 dashboard-1860.json  # Node Exporter Full\n\u2502   \u2502       \u251c\u2500\u2500 dashboard-179.json   # Docker &amp; System\n\u2502   \u2502       \u251c\u2500\u2500 dashboard-893.json   # cAdvisor\n\u2502   \u2502       \u2514\u2500\u2500 dashboard-15172.json # Node Exporter Quickstart\n\u2502   \u2514\u2500\u2500 datasources/\n\u2502       \u2514\u2500\u2500 prometheus.yml          # Prometheus datasource\n</code></pre>"},{"location":"grafana-dashboards/#customization","title":"\ud83d\udd27 Customization","text":""},{"location":"grafana-dashboards/#modify-dashboard-variables","title":"Modify Dashboard Variables","text":"<p>Dashboards use template variables for dynamic filtering:</p> <ol> <li>Edit a dashboard in Grafana UI</li> <li>Click Settings \u2699\ufe0f \u2192 Variables</li> <li>Modify existing variables or add new ones:</li> <li><code>instance</code> - Select specific servers</li> <li><code>container</code> - Filter by container name</li> <li><code>device</code> - Choose network/disk devices</li> <li><code>interval</code> - Adjust scrape intervals</li> </ol>"},{"location":"grafana-dashboards/#change-refresh-rate","title":"Change Refresh Rate","text":"<ol> <li>Click Dashboard settings \u2699\ufe0f</li> <li>Go to Time options</li> <li>Set Auto refresh: <code>5s, 10s, 30s, 1m, 5m</code></li> <li>Save dashboard</li> </ol>"},{"location":"grafana-dashboards/#add-annotations","title":"Add Annotations","text":"<p>Display alert events on graphs:</p> <ol> <li>Settings \u2699\ufe0f \u2192 Annotations</li> <li>Add new annotation query:    <pre><code>ALERTS{alertstate=\"firing\"}\n</code></pre></li> <li>Alerts will appear as vertical lines on graphs</li> </ol>"},{"location":"grafana-dashboards/#clone-and-modify","title":"Clone and Modify","text":"<p>To create custom versions:</p> <ol> <li>Open dashboard \u2192 Share icon</li> <li>Click Export \u2192 Save to file</li> <li>Edit JSON file (change title, panels, queries)</li> <li>Import via Dashboards \u2192 Import \u2192 Upload JSON</li> </ol>"},{"location":"grafana-dashboards/#dashboard-best-practices","title":"\ud83c\udfa8 Dashboard Best Practices","text":""},{"location":"grafana-dashboards/#do","title":"DO \u2705","text":"<ul> <li>Use folders - Organize by team/service (Imported, Custom, SRE)</li> <li>Set time ranges - Default to Last 6 hours for operational dashboards</li> <li>Enable auto-refresh - 30s-1m for real-time monitoring</li> <li>Add descriptions - Use panel descriptions for query explanations</li> <li>Version control - Export dashboards to Git after changes</li> <li>Use variables - Make dashboards reusable across environments</li> </ul>"},{"location":"grafana-dashboards/#dont","title":"DON'T \u274c","text":"<ul> <li>Overload panels - Max 12 panels per row for readability</li> <li>Use default titles - Rename \"Panel Title\" to meaningful names</li> <li>Hardcode instances - Always use variables like <code>$instance</code></li> <li>Mix time ranges - Keep all panels on same time window</li> <li>Forget alerts - Link related alerts to dashboard panels</li> <li>Skip legends - Always label graph series clearly</li> </ul>"},{"location":"grafana-dashboards/#example-creating-a-custom-dashboard","title":"\ud83d\udcca Example: Creating a Custom Dashboard","text":""},{"location":"grafana-dashboards/#step-1-start-from-template","title":"Step 1: Start from Template","text":"<pre><code># Import Node Exporter Full as base\n# Open in Grafana \u2192 Save As \u2192 \"My Custom Dashboard\"\n</code></pre>"},{"location":"grafana-dashboards/#step-2-add-custom-panel","title":"Step 2: Add Custom Panel","text":"<ol> <li>Click Add panel \u2192 Add new visualization</li> <li>Write Prometheus query:    <pre><code>rate(container_cpu_usage_seconds_total{name=\"mon-prometheus\"}[5m]) * 100\n</code></pre></li> <li>Set Panel title: \"Prometheus CPU Usage\"</li> <li>Choose Visualization: Time series</li> <li>Configure Thresholds: 50% (yellow), 80% (red)</li> <li>Click Apply</li> </ol>"},{"location":"grafana-dashboards/#step-3-add-business-metrics","title":"Step 3: Add Business Metrics","text":"<p>Example: Application request rate</p> <pre><code>sum(rate(http_requests_total[5m])) by (service)\n</code></pre>"},{"location":"grafana-dashboards/#step-4-export-and-version","title":"Step 4: Export and Version","text":"<pre><code># Export dashboard JSON\n# Save to: docker/monitoring-stack/grafana/provisioning/dashboards/json/custom-app.json\n\n# Commit to Git\ngit add docker/monitoring-stack/grafana/provisioning/dashboards/json/custom-app.json\ngit commit -m \"feat(grafana): add custom application dashboard\"\n</code></pre>"},{"location":"grafana-dashboards/#integration-with-prometheus","title":"\ud83d\udd17 Integration with Prometheus","text":""},{"location":"grafana-dashboards/#verify-datasource","title":"Verify Datasource","text":"<p>Check Prometheus datasource is configured:</p> <pre><code># View datasource config\ncat docker/monitoring-stack/grafana/provisioning/datasources/prometheus.yml\n</code></pre> <p>Expected output:</p> <pre><code>apiVersion: 1\n\ndatasources:\n  - name: Prometheus\n    type: prometheus\n    access: proxy\n    url: http://prometheus:9090\n    isDefault: true\n</code></pre>"},{"location":"grafana-dashboards/#test-queries","title":"Test Queries","text":"<p>In Grafana Explore view, test queries:</p> <pre><code># All available metrics\n{__name__=~\".+\"}\n\n# Node Exporter metrics\nnode_cpu_seconds_total\n\n# cAdvisor metrics\ncontainer_memory_usage_bytes\n\n# Custom app metrics (if instrumented)\nmyapp_http_requests_total\n</code></pre>"},{"location":"grafana-dashboards/#troubleshooting","title":"\ud83d\udee0\ufe0f Troubleshooting","text":""},{"location":"grafana-dashboards/#dashboards-not-appearing","title":"Dashboards Not Appearing","text":"<p>Problem: Dashboards don't show in Grafana UI</p> <p>Solution:</p> <ol> <li> <p>Check provisioning directory:    <pre><code>ls -la docker/monitoring-stack/grafana/provisioning/dashboards/json/\n</code></pre></p> </li> <li> <p>Verify dashboard provider config exists:    <pre><code>cat docker/monitoring-stack/grafana/provisioning/dashboards/dashboards.yml\n</code></pre></p> </li> <li> <p>Check Grafana logs:    <pre><code>docker logs mon-grafana | grep -i dashboard\n</code></pre></p> </li> <li> <p>Restart Grafana:    <pre><code>docker compose -f docker/monitoring-stack/docker-compose.yml restart grafana\n</code></pre></p> </li> </ol>"},{"location":"grafana-dashboards/#no-data-in-panels","title":"\"No Data\" in Panels","text":"<p>Problem: Dashboard loads but panels show \"No data\"</p> <p>Solution:</p> <ol> <li>Verify Prometheus is scraping targets:</li> <li>Open http://localhost:9090/targets</li> <li> <p>All targets should be UP</p> </li> <li> <p>Check metric names in Prometheus:    <pre><code># Search for node_exporter metrics\n{job=\"node-exporter\"}\n</code></pre></p> </li> <li> <p>Adjust time range:</p> </li> <li>Click time picker (top-right)</li> <li> <p>Select Last 6 hours or Last 24 hours</p> </li> <li> <p>Verify datasource in panel:</p> </li> <li>Edit panel \u2192 Query tab</li> <li>Datasource should be Prometheus (not <code>-- Mixed --</code>)</li> </ol>"},{"location":"grafana-dashboards/#slow-dashboard-loading","title":"Slow Dashboard Loading","text":"<p>Problem: Dashboards take &gt;10 seconds to load</p> <p>Solution:</p> <ol> <li>Reduce time range (Last 1 hour instead of Last 7 days)</li> <li>Increase scrape interval in <code>prometheus.yml</code>:    <pre><code>scrape_configs:\n  - job_name: node-exporter\n    scrape_interval: 30s  # Instead of 15s\n</code></pre></li> <li> <p>Enable query caching in Grafana:    <pre><code># grafana.ini\n[caching]\nenabled = true\n</code></pre></p> </li> <li> <p>Optimize PromQL queries (use <code>rate()</code> instead of <code>irate()</code> for less data points)</p> </li> </ol>"},{"location":"grafana-dashboards/#additional-resources","title":"\ud83d\udcda Additional Resources","text":""},{"location":"grafana-dashboards/#official-documentation","title":"Official Documentation","text":"<ul> <li>Grafana Dashboards Guide</li> <li>Prometheus Query Examples</li> <li>Dashboard Best Practices</li> </ul>"},{"location":"grafana-dashboards/#community-dashboards","title":"Community Dashboards","text":"<p>Browse 10,000+ dashboards: - Grafana.com Dashboard Library - Filter by: Data source (Prometheus), Tags (docker, linux, kubernetes)</p>"},{"location":"grafana-dashboards/#video-tutorials","title":"Video Tutorials","text":"<ul> <li>Grafana Fundamentals</li> <li>Building Your First Dashboard</li> </ul>"},{"location":"grafana-dashboards/#next-steps","title":"\ud83c\udfaf Next Steps","text":"<ol> <li>Explore dashboards - Click through all 4 imported dashboards</li> <li>Customize variables - Adjust filters for your environment</li> <li>Create alerts - Add alerting rules to dashboard panels</li> <li>Export and backup - Save dashboards to Git for version control</li> <li>Share dashboards - Generate snapshot links for team sharing</li> </ol> <p>Pro Tip: Set your most-used dashboard as Home Dashboard in Grafana preferences for quick access on login!</p>"},{"location":"hire-me/","title":"Hire Me","text":"<p>Stephon \"Skip\" Skipper \u2014 DevOps Engineer</p> <ul> <li>3+ yrs Linux sysadmin \u00b7 IaC (Terraform/Ansible) \u00b7 CI/CD (Jenkins/GitHub Actions)  </li> <li>Homelab: Proxmox cluster, NFS, Docker, Prometheus/Grafana monitoring, security automation</li> <li>Focus: infrastructure automation, observability, security, and reliability</li> </ul> <p>Recent Highlights</p> <ul> <li>Full-Stack Monitoring: Prometheus + Grafana stack with automated Node Exporter deployment via Ansible</li> <li>Infrastructure as Code: Terraform modules with built-in testing and security scanning</li> <li>Security Automation: Zero-SSH EC2 (IMDSv2, encrypted volumes, SSM), systemd hardening, SELinux configurations</li> <li>CI/CD Excellence: Automated validation with TFLint, Checkov, Hadolint, ansible-lint, yamllint</li> <li>Configuration Management: Idempotent Ansible roles with firewall automation and health checks</li> <li>Documentation: Live documentation site with interactive diagrams and complete examples</li> </ul> <p>Portfolio</p> <ul> <li>\ud83d\udcd6 Live Documentation</li> <li>\ud83d\udcbb GitHub Repository</li> <li>\ud83c\udf10 Personal Site</li> </ul> <p>Contact</p> <ul> <li>\ud83d\udcbc LinkedIn: linkedin.com/in/stephon-skipper</li> <li>\ud83d\udce7 Email: stephon@ayoskip.info </li> <li>\ud83d\udc19 GitHub: iso-st3ph</li> </ul> <p>Why Hire Me?</p> <p>I don't just know the tools\u2014I build production-ready infrastructure that demonstrates real-world DevOps practices. This portfolio showcases end-to-end automation from infrastructure provisioning to monitoring, all with security best practices and comprehensive documentation.</p>"},{"location":"jenkins/","title":"Jenkins CI/CD on Kubernetes","text":"<p>Production-ready Jenkins deployment on K3s with dynamic Kubernetes agent provisioning and comprehensive CI/CD pipelines.</p>"},{"location":"jenkins/#overview","title":"\ud83c\udfaf Overview","text":"<p>This Jenkins implementation demonstrates cloud-native CI/CD with:</p> <ul> <li>Jenkins Controller on Kubernetes - LTS version with persistent storage</li> <li>Dynamic Agent Provisioning - Kubernetes plugin spawns pods on-demand</li> <li>Configuration as Code - JCasC for reproducible setups</li> <li>Multi-stage Pipelines - Terraform, Ansible, security scanning, K8s validation</li> <li>GitOps Management - ArgoCD manages Jenkins deployment</li> </ul>"},{"location":"jenkins/#architecture","title":"\ud83c\udfd7\ufe0f Architecture","text":"<pre><code>graph TB\n    subgraph \"Development\"\n        DEV[Developer]\n        GIT[GitHub Repository]\n    end\n\n    subgraph \"Jenkins CI/CD\"\n        JENKINS[Jenkins Controller&lt;br/&gt;LTS on K8s]\n        AGENT[Kubernetes Agents&lt;br/&gt;Dynamic Pods]\n    end\n\n    subgraph \"Pipeline Stages\"\n        TERRAFORM[Terraform&lt;br/&gt;Validate &amp; Test]\n        ANSIBLE[Ansible&lt;br/&gt;Syntax Check]\n        TRIVY[Trivy&lt;br/&gt;Security Scan]\n        KUBECTL[kubectl&lt;br/&gt;K8s Validation]\n    end\n\n    subgraph \"GitOps\"\n        ARGO[ArgoCD]\n    end\n\n    DEV --&gt;|Push Code| GIT\n    GIT --&gt;|Webhook/Poll| JENKINS\n    JENKINS --&gt;|Spawn Pod| AGENT\n    AGENT --&gt;|Stage 1| TERRAFORM\n    AGENT --&gt;|Stage 2| ANSIBLE\n    AGENT --&gt;|Stage 3| TRIVY\n    AGENT --&gt;|Stage 4| KUBECTL\n    ARGO --&gt;|Manages| JENKINS\n    ARGO &lt;--&gt;|Syncs| GIT</code></pre>"},{"location":"jenkins/#components","title":"\ud83d\udce6 Components","text":""},{"location":"jenkins/#jenkins-controller","title":"Jenkins Controller","text":"<p>Deployment Configuration:</p> <ul> <li>Image: <code>jenkins/jenkins:lts</code></li> <li>Replicas: 1 (stateful application)</li> <li>Resources: 500m CPU / 1Gi RAM (request), 2 CPU / 3Gi RAM (limit)</li> <li>Storage: 20Gi PersistentVolumeClaim (local-path storage class)</li> <li>Ports: 8080 (UI), 50000 (JNLP for agents)</li> <li>Access: NodePort 30808</li> </ul>"},{"location":"jenkins/#kubernetes-plugin","title":"Kubernetes Plugin","text":"<p>Dynamic Agent Provisioning:</p> <ul> <li>Spawns pods in <code>jenkins</code> namespace on-demand</li> <li>Auto-cleanup after job completion</li> <li>Max 10 concurrent agents</li> <li>Resource limits: 500m CPU / 512Mi RAM per agent</li> <li>JNLP tunnel for controller-agent communication</li> </ul>"},{"location":"jenkins/#pipeline-containers","title":"Pipeline Containers","text":"<p>Each agent pod includes specialized containers:</p> <ul> <li>terraform - <code>hashicorp/terraform:latest</code> for IaC validation/testing</li> <li>ansible - <code>cytopia/ansible:latest</code> for playbook syntax checks</li> <li>trivy - <code>aquasec/trivy:latest</code> for security scanning</li> <li>kubectl - <code>bitnami/kubectl:latest</code> for K8s manifest validation</li> </ul>"},{"location":"jenkins/#deployment","title":"\ud83d\ude80 Deployment","text":""},{"location":"jenkins/#quick-start","title":"Quick Start","text":"<pre><code># Deploy Jenkins\nmake jenkins-deploy\n\n# Check status\nmake jenkins-status\n\n# View logs\nmake jenkins-logs\n\n# Get UI access details\nmake jenkins-ui\n</code></pre>"},{"location":"jenkins/#gitops-deployment","title":"GitOps Deployment","text":"<pre><code># Deploy via ArgoCD\nmake jenkins-app\n\n# Check ArgoCD sync status\nkubectl get application jenkins -n argocd\n</code></pre>"},{"location":"jenkins/#manual-deployment","title":"Manual Deployment","text":"<pre><code>cd kubernetes/jenkins\n\n# Apply all manifests\nkubectl apply -f .\n\n# Wait for pod ready\nkubectl wait --for=condition=ready pod -l app=jenkins -n jenkins --timeout=300s\n</code></pre>"},{"location":"jenkins/#configuration","title":"\ud83d\udd27 Configuration","text":""},{"location":"jenkins/#jenkins-configuration-as-code-jcasc","title":"Jenkins Configuration as Code (JCasC)","text":"<p>Jenkins is configured via JCasC (<code>kubernetes/jenkins/03-configmap.yaml</code>):</p> <pre><code>jenkins:\n  systemMessage: \"Jenkins - DevOps Portfolio CI/CD Server\"\n  numExecutors: 0  # All jobs run on Kubernetes agents\n  clouds:\n    - kubernetes:\n        name: \"kubernetes\"\n        serverUrl: \"https://kubernetes.default\"\n        namespace: \"jenkins\"\n        containerCapStr: \"10\"\n        templates:\n          - name: \"jenkins-agent\"\n            containers:\n              - name: \"jnlp\"\n                image: \"jenkins/inbound-agent:latest\"\n                resourceRequestCpu: \"500m\"\n                resourceRequestMemory: \"512Mi\"\n</code></pre> <p>Benefits:</p> <ul> <li>\u2705 No manual setup wizard</li> <li>\u2705 Reproducible configuration</li> <li>\u2705 Version controlled in Git</li> <li>\u2705 Easy to update and redeploy</li> </ul>"},{"location":"jenkins/#rbac-permissions","title":"RBAC Permissions","text":"<p>Jenkins ServiceAccount has ClusterRole permissions for:</p> <ul> <li>Pods: create, delete, get, list, patch, update, watch</li> <li>Pods/exec: Full access for running commands in agents</li> <li>Pods/log: Read logs from agent pods</li> <li>Secrets: Manage credentials</li> <li>ConfigMaps: Manage configuration</li> <li>PVCs: Manage persistent storage</li> </ul>"},{"location":"jenkins/#cicd-pipeline","title":"\ud83d\udccb CI/CD Pipeline","text":""},{"location":"jenkins/#jenkinsfile-overview","title":"Jenkinsfile Overview","text":"<p>The root <code>Jenkinsfile</code> demonstrates a complete CI/CD pipeline:</p> <p>Stages:</p> <ol> <li>Checkout - Clone repository from Git</li> <li>Terraform Validation - Format check, init, validate</li> <li>Terraform Test - Run module tests</li> <li>Ansible Syntax Check - Validate all playbooks</li> <li>Security Scan - IaC - Trivy config scanning (Terraform + K8s)</li> <li>Security Scan - Images - Trivy container image scanning</li> <li>Kubernetes Validation - kubectl dry-run validation</li> <li>Summary - Report pipeline results</li> </ol>"},{"location":"jenkins/#example-pipeline-definition","title":"Example Pipeline Definition","text":"<pre><code>pipeline {\n  agent {\n    kubernetes {\n      yaml '''\n        # Pod spec with terraform, ansible, trivy, kubectl containers\n      '''\n    }\n  }\n\n  stages {\n    stage('Terraform Validation') {\n      steps {\n        container('terraform') {\n          sh '''\n            terraform init -backend=false\n            terraform validate\n            terraform fmt -check\n          '''\n        }\n      }\n    }\n\n    stage('Security Scan') {\n      steps {\n        container('trivy') {\n          sh 'trivy config terraform/'\n        }\n      }\n    }\n  }\n\n  post {\n    always {\n      cleanWs()\n    }\n  }\n}\n</code></pre>"},{"location":"jenkins/#running-the-pipeline","title":"Running the Pipeline","text":"<ol> <li>Create Pipeline Job in Jenkins UI</li> <li>Configure \u2192 Pipeline from SCM \u2192 Git</li> <li>Repository URL: <code>https://github.com/iso-st3ph/homelab-devops.git</code></li> <li>Branch: <code>main</code></li> <li>Script Path: <code>Jenkinsfile</code></li> <li>Save and Build Now</li> </ol>"},{"location":"jenkins/#monitoring-operations","title":"\ud83d\udcca Monitoring &amp; Operations","text":""},{"location":"jenkins/#check-deployment-status","title":"Check Deployment Status","text":"<pre><code># Pods\nkubectl get pods -n jenkins\n\n# Services\nkubectl get svc -n jenkins\n\n# PersistentVolumeClaims\nkubectl get pvc -n jenkins\n\n# Full status\nmake jenkins-status\n</code></pre>"},{"location":"jenkins/#view-logs","title":"View Logs","text":"<pre><code># Controller logs\nkubectl logs -n jenkins -l app=jenkins -f\n\n# Or via Makefile\nmake jenkins-logs\n\n# Agent logs (during job)\nkubectl logs -n jenkins &lt;agent-pod-name&gt; -c terraform\n</code></pre>"},{"location":"jenkins/#access-jenkins-ui","title":"Access Jenkins UI","text":"<pre><code>URL: http://localhost:30808\n</code></pre> <p>Since JCasC disables the setup wizard, Jenkins starts ready to use. Create jobs directly or configure authentication as needed.</p>"},{"location":"jenkins/#restart-jenkins","title":"Restart Jenkins","text":"<pre><code># Rollout restart (zero downtime)\nkubectl rollout restart deployment/jenkins -n jenkins\n\n# Check rollout status\nkubectl rollout status deployment/jenkins -n jenkins\n</code></pre>"},{"location":"jenkins/#security-features","title":"\ud83d\udd10 Security Features","text":""},{"location":"jenkins/#container-security","title":"Container Security","text":"<ul> <li>Non-root user - Jenkins runs as UID 1000</li> <li>Read-only ConfigMap - Configuration mounted read-only</li> <li>Resource limits - CPU/memory limits prevent resource exhaustion</li> <li>Security scanning - Trivy scans in pipeline</li> </ul>"},{"location":"jenkins/#rbac","title":"RBAC","text":"<ul> <li>ServiceAccount - Dedicated <code>jenkins</code> service account</li> <li>ClusterRole - Scoped permissions for pod/secret management</li> <li>Namespace isolation - Jenkins runs in dedicated namespace</li> </ul>"},{"location":"jenkins/#secrets-management","title":"Secrets Management","text":"<pre><code># Create secret for credentials\nkubectl create secret generic github-token \\\n  --from-literal=token='ghp_xxxxxxxxxxxx' \\\n  -n jenkins\n\n# Reference in pipeline\nwithCredentials([string(credentialsId: 'github-token', variable: 'TOKEN')]) {\n  sh 'echo $TOKEN'\n}\n</code></pre>"},{"location":"jenkins/#best-practices","title":"\ud83c\udfaf Best Practices","text":""},{"location":"jenkins/#pipeline-design","title":"Pipeline Design","text":"<p>\u2705 Use Kubernetes agents - Don't run jobs on controller (numExecutors: 0) \u2705 Container per tool - Separate containers for Terraform, Ansible, etc. \u2705 Resource limits - Set CPU/memory limits on agents \u2705 Clean workspace - Use <code>cleanWs()</code> in post-always \u2705 Timeout stages - Prevent hung jobs \u2705 Parallel stages - Speed up pipeline with parallel execution</p>"},{"location":"jenkins/#configuration_1","title":"Configuration","text":"<p>\u2705 Use JCasC - Configuration as Code in version control \u2705 Persistent storage - PVC for jenkins_home \u2705 Health checks - Liveness and readiness probes \u2705 GitOps - Manage Jenkins deployment via ArgoCD \u2705 Immutable tags - Pin container image versions</p>"},{"location":"jenkins/#security","title":"Security","text":"<p>\u2705 Scan dependencies - Trivy/Checkov in pipeline \u2705 RBAC - Minimal permissions for ServiceAccount \u2705 Secrets - Use Kubernetes secrets, not hardcoded values \u2705 Network policies - Restrict pod-to-pod communication (optional) \u2705 Audit logs - Enable Jenkins audit trail plugin</p>"},{"location":"jenkins/#troubleshooting","title":"\ud83d\udee0\ufe0f Troubleshooting","text":""},{"location":"jenkins/#jenkins-pod-not-starting","title":"Jenkins Pod Not Starting","text":"<p>Check pod status:</p> <pre><code>kubectl describe pod -n jenkins &lt;pod-name&gt;\nkubectl logs -n jenkins &lt;pod-name&gt;\n</code></pre> <p>Common issues:</p> <ul> <li>PVC not bound \u2192 Check storage class exists</li> <li>Resource limits too low \u2192 Increase CPU/RAM</li> <li>Image pull errors \u2192 Check image availability</li> </ul>"},{"location":"jenkins/#agents-not-spawning","title":"Agents Not Spawning","text":"<p>Check:</p> <ol> <li>ServiceAccount has correct RBAC \u2192 <code>kubectl describe clusterrole jenkins</code></li> <li>Kubernetes plugin configured \u2192 JCasC in ConfigMap</li> <li>Jenkins URL accessible \u2192 <code>http://jenkins:8080</code> from pods</li> <li>JNLP port open \u2192 Service exposes port 50000</li> </ol> <p>Debug:</p> <pre><code># Check plugin configuration\nkubectl exec -n jenkins &lt;jenkins-pod&gt; -- cat /var/jenkins_config/jenkins.yaml\n\n# Test connectivity\nkubectl run test-pod --rm -it --image=busybox -- wget -O- http://jenkins:8080\n</code></pre>"},{"location":"jenkins/#ui-not-accessible","title":"UI Not Accessible","text":"<p>Port forward as alternative:</p> <pre><code>kubectl port-forward -n jenkins svc/jenkins 8080:8080\n# Access at http://localhost:8080\n</code></pre> <p>Check NodePort:</p> <pre><code>kubectl get svc jenkins -n jenkins\n# Verify nodePort is 30808\n</code></pre>"},{"location":"jenkins/#pipeline-fails-with-permission-denied","title":"Pipeline Fails with Permission Denied","text":"<p>Increase RBAC permissions:</p> <pre><code># Edit ClusterRole\nkubectl edit clusterrole jenkins\n\n# Add additional resource permissions as needed\n</code></pre>"},{"location":"jenkins/#scaling-performance","title":"\ud83d\udcc8 Scaling &amp; Performance","text":""},{"location":"jenkins/#horizontal-scaling","title":"Horizontal Scaling","text":"<p>\u274c Don't scale Jenkins controller replicas (stateful) \u2705 Scale agents by increasing <code>containerCapStr</code> in JCasC</p>"},{"location":"jenkins/#vertical-scaling","title":"Vertical Scaling","text":"<p>Increase controller resources in deployment:</p> <pre><code>resources:\n  requests:\n    cpu: 1000m\n    memory: 2Gi\n  limits:\n    cpu: 4000m\n    memory: 6Gi\n</code></pre>"},{"location":"jenkins/#performance-tuning","title":"Performance Tuning","text":"<ul> <li>Increase agent capacity - Raise <code>containerCapStr</code> to 20+</li> <li>Use node selectors - Pin agents to specific nodes</li> <li>Enable caching - Cache dependencies between builds</li> <li>Optimize pipelines - Parallel stages, skip unnecessary steps</li> </ul>"},{"location":"jenkins/#skills-demonstrated","title":"\ud83c\udf93 Skills Demonstrated","text":"<ul> <li>\u2705 Jenkins on Kubernetes - Cloud-native CI/CD platform</li> <li>\u2705 Dynamic Agent Provisioning - Kubernetes plugin with pod templates</li> <li>\u2705 Configuration as Code - JCasC for reproducible setup</li> <li>\u2705 Declarative Pipelines - Groovy-based Jenkinsfile</li> <li>\u2705 Multi-stage CI/CD - Validate \u2192 Test \u2192 Scan \u2192 Deploy</li> <li>\u2705 Container-based Jobs - Specialized containers per stage</li> <li>\u2705 Security Integration - Trivy scanning in pipeline</li> <li>\u2705 GitOps Workflow - ArgoCD managing Jenkins deployment</li> <li>\u2705 RBAC - Kubernetes service account and role bindings</li> <li>\u2705 Persistent Storage - PVC for stateful data</li> </ul>"},{"location":"jenkins/#references","title":"\ud83d\udcda References","text":"<ul> <li>Jenkins on Kubernetes</li> <li>Kubernetes Plugin Documentation</li> <li>Jenkins Configuration as Code</li> <li>Pipeline Syntax Reference</li> <li>Declarative Pipeline</li> </ul> <p>Built by Stephon Skipper | GitHub</p>"},{"location":"kubernetes/","title":"Kubernetes (K3s) Deployment","text":"<p>This guide covers the Kubernetes deployment of our complete observability stack using K3s, a lightweight Kubernetes distribution perfect for homelabs and edge computing.</p>"},{"location":"kubernetes/#overview","title":"\ud83c\udfaf Overview","text":"<p>We've deployed a production-grade monitoring stack on Kubernetes, demonstrating cloud-native orchestration skills essential for modern DevOps roles.</p> <p>Cluster Details:</p> <ul> <li>Distribution: K3s v1.33.5+k3s1</li> <li>Nodes: Single-node cluster (can scale to multi-node)</li> <li>Services: 5 core observability services</li> <li>Storage: 50Gi total with PersistentVolumeClaims</li> <li>Access: NodePort services for external access</li> </ul>"},{"location":"kubernetes/#deployed-services","title":"\ud83d\udcca Deployed Services","text":"Service Purpose Type Access Prometheus Metrics collection &amp; storage NodePort <code>http://localhost:30090</code> Grafana Visualization &amp; dashboards NodePort <code>http://localhost:30300</code> Loki Log aggregation ClusterIP Internal (3100) Tempo Distributed tracing ClusterIP Internal (3200, 4317, 4318) AlertManager Alert routing NodePort <code>http://localhost:30093</code>"},{"location":"kubernetes/#architecture","title":"\ud83c\udfd7\ufe0f Architecture","text":"<pre><code>graph TB\n    subgraph K3s Cluster\n        subgraph Monitoring Namespace\n            P[Prometheus&lt;br/&gt;Deployment]\n            G[Grafana&lt;br/&gt;Deployment]\n            L[Loki&lt;br/&gt;Deployment]\n            T[Tempo&lt;br/&gt;Deployment]\n            A[AlertManager&lt;br/&gt;Deployment]\n\n            P --&gt; PPVC[prometheus-pvc&lt;br/&gt;10Gi]\n            G --&gt; GPVC[grafana-pvc&lt;br/&gt;5Gi]\n            L --&gt; LPVC[loki-pvc&lt;br/&gt;20Gi]\n            T --&gt; TPVC[tempo-pvc&lt;br/&gt;20Gi]\n            A --&gt; APVC[alertmanager-pvc&lt;br/&gt;2Gi]\n        end\n\n        subgraph ConfigMaps\n            PC[prometheus-config]\n            PR[prometheus-rules]\n            GD[grafana-datasources]\n            LC[loki-config]\n            TC[tempo-config]\n            AC[alertmanager-config]\n        end\n\n        P -.-&gt;|uses| PC\n        P -.-&gt;|uses| PR\n        G -.-&gt;|uses| GD\n        L -.-&gt;|uses| LC\n        T -.-&gt;|uses| TC\n        A -.-&gt;|uses| AC\n    end\n\n    subgraph External Access\n        NP1[NodePort 30090]\n        NP2[NodePort 30300]\n        NP3[NodePort 30093]\n    end\n\n    P --&gt; NP1\n    G --&gt; NP2\n    A --&gt; NP3\n\n    G --&gt;|queries| P\n    G --&gt;|queries| L\n    G --&gt;|queries| T\n    P --&gt;|alerts| A</code></pre>"},{"location":"kubernetes/#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"kubernetes/#deploy-the-stack","title":"Deploy the Stack","text":"<pre><code># From repository root\nmake k8s-deploy\n</code></pre> <p>This will:</p> <ol> <li>Connect to K3s cluster</li> <li>Create <code>monitoring</code> namespace</li> <li>Apply all manifests in order</li> <li>Wait for pods to be ready</li> <li>Display access URLs</li> </ol>"},{"location":"kubernetes/#check-status","title":"Check Status","text":"<pre><code># View all resources\nmake k8s-status\n\n# Or manually\nkubectl get all -n monitoring\nkubectl get pvc -n monitoring\n</code></pre>"},{"location":"kubernetes/#access-services","title":"Access Services","text":"<ul> <li>Prometheus: http://localhost:30090</li> <li>Grafana: http://localhost:30300 (admin/admin)</li> <li>AlertManager: http://localhost:30093</li> </ul>"},{"location":"kubernetes/#configuration-highlights","title":"\ud83d\udd27 Configuration Highlights","text":""},{"location":"kubernetes/#prometheus-configuration","title":"Prometheus Configuration","text":"<p>Service Discovery:</p> <ul> <li>Kubernetes API servers (auto-discovery)</li> <li>Kubernetes nodes (kubelet metrics)</li> <li>Kubernetes pods (annotation-based)</li> <li>Static configs for monitoring services</li> </ul> <p>RBAC Permissions:</p> <ul> <li>ClusterRole with read access to nodes, services, endpoints, pods</li> <li>ServiceAccount: <code>prometheus</code></li> <li>ClusterRoleBinding for cross-namespace discovery</li> </ul> <p>External Labels:</p> <pre><code>external_labels:\n  cluster: 'k3s-homelab'\n  environment: 'production'\n</code></pre> <p>Storage:</p> <ul> <li>10Gi PersistentVolumeClaim (local-path storage class)</li> <li>15-day retention (<code>--storage.tsdb.retention.time=15d</code>)</li> </ul>"},{"location":"kubernetes/#grafana-configuration","title":"Grafana Configuration","text":"<p>Auto-Provisioned Datasources:</p> <ol> <li>Prometheus - Default datasource for metrics</li> <li>Loki - Log aggregation with trace correlation</li> <li>Tempo - Distributed tracing with full correlation</li> </ol> <p>Correlation Features:</p> <ul> <li>Trace \u2192 Logs (via Loki, with tag mapping)</li> <li>Trace \u2192 Metrics (via Prometheus)</li> <li>Logs \u2192 Traces (via Tempo)</li> <li>Service Maps and Node Graphs enabled</li> </ul> <p>Plugins:</p> <ul> <li><code>grafana-piechart-panel</code> (auto-installed)</li> </ul>"},{"location":"kubernetes/#loki-configuration","title":"Loki Configuration","text":"<p>Retention: 30 days (720h)</p> <p>Schema: TSDB v13 (modern, efficient storage)</p> <p>Compaction:</p> <ul> <li>Interval: 10 minutes</li> <li>Delete request store: filesystem</li> <li>Retention cleanup enabled</li> </ul> <p>Storage: 20Gi PVC with local filesystem backend</p>"},{"location":"kubernetes/#tempo-configuration","title":"Tempo Configuration","text":"<p>Receivers:</p> <ul> <li>OTLP gRPC: Port 4317</li> <li>OTLP HTTP: Port 4318</li> </ul> <p>Metrics Generator:</p> <ul> <li>Service graphs with histogram buckets</li> <li>Span metrics for latency analysis</li> <li>Remote write to Prometheus</li> </ul> <p>Storage: 20Gi PVC with 30-day retention</p>"},{"location":"kubernetes/#alertmanager-configuration","title":"AlertManager Configuration","text":"<p>Routing:</p> <ul> <li>Critical alerts: 5m repeat interval</li> <li>Warning alerts: 1h repeat interval</li> <li>Grouped by: alertname, cluster, service</li> </ul> <p>Inhibition Rules:</p> <ul> <li>Critical alerts suppress warnings for same instance</li> </ul>"},{"location":"kubernetes/#kubernetes-manifests","title":"\ud83d\udccb Kubernetes Manifests","text":"<p>Our deployment uses declarative manifests organized by component:</p> <pre><code>kubernetes/monitoring/\n\u251c\u2500\u2500 00-namespace.yaml              # Monitoring namespace\n\u251c\u2500\u2500 01-prometheus-configmap.yaml   # Prometheus config + K8s SD\n\u251c\u2500\u2500 02-prometheus-rules.yaml       # Alert rules (K8s + system)\n\u251c\u2500\u2500 03-prometheus.yaml             # Deployment + PVC + Service + RBAC\n\u251c\u2500\u2500 04-grafana.yaml                # Deployment + PVC + Service + ConfigMap\n\u251c\u2500\u2500 05-node-exporter.yaml          # DaemonSet (removed due to port conflict)\n\u251c\u2500\u2500 06-loki.yaml                   # Deployment + PVC + Service + ConfigMap\n\u251c\u2500\u2500 07-tempo.yaml                  # Deployment + PVC + Service + ConfigMap\n\u251c\u2500\u2500 08-alertmanager.yaml           # Deployment + PVC + Service + ConfigMap\n\u251c\u2500\u2500 deploy.sh                      # Automated deployment script\n\u2514\u2500\u2500 README.md                      # Detailed documentation\n</code></pre>"},{"location":"kubernetes/#kubernetes-specific-features","title":"\ud83c\udfaf Kubernetes-Specific Features","text":""},{"location":"kubernetes/#pod-auto-discovery","title":"Pod Auto-Discovery","text":"<p>Prometheus automatically discovers pods with these annotations:</p> <pre><code>annotations:\n  prometheus.io/scrape: \"true\"\n  prometheus.io/port: \"8080\"\n  prometheus.io/path: \"/metrics\"\n</code></pre>"},{"location":"kubernetes/#alert-rules-for-kubernetes","title":"Alert Rules for Kubernetes","text":"<p>Pre-configured alerts in <code>02-prometheus-rules.yaml</code>:</p> <ul> <li>PodCrashLooping - Pod restarting frequently</li> <li>PodNotReady - Pod not ready for 10+ minutes</li> <li>NodeExporterDown - Node metrics unavailable</li> <li>HighCPUUsage - CPU &gt; 80% for 5 minutes</li> <li>HighMemoryUsage - Memory &gt; 90% for 5 minutes</li> <li>DiskSpaceLow - Disk &lt; 15% available</li> </ul>"},{"location":"kubernetes/#resource-limits","title":"Resource Limits","text":"<p>All deployments have proper resource requests/limits:</p> <pre><code>resources:\n  requests:\n    cpu: 250m\n    memory: 512Mi\n  limits:\n    cpu: 1000m\n    memory: 2Gi\n</code></pre>"},{"location":"kubernetes/#health-checks","title":"Health Checks","text":"<p>Liveness and readiness probes configured for all services:</p> <pre><code>livenessProbe:\n  httpGet:\n    path: /-/healthy\n    port: 9090\n  initialDelaySeconds: 30\n  periodSeconds: 10\n</code></pre>"},{"location":"kubernetes/#querying-kubernetes-metrics","title":"\ud83d\udd0d Querying Kubernetes Metrics","text":""},{"location":"kubernetes/#example-promql-queries","title":"Example PromQL Queries","text":"<p>Pod Status:</p> <pre><code>kube_pod_status_phase{namespace=\"monitoring\"}\n</code></pre> <p>Pod Restart Count:</p> <pre><code>kube_pod_container_status_restarts_total{namespace=\"monitoring\"}\n</code></pre> <p>Node CPU Usage:</p> <pre><code>100 - (avg by (instance) (irate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100)\n</code></pre>"},{"location":"kubernetes/#grafana-dashboards","title":"Grafana Dashboards","text":"<p>Import these Kubernetes-focused dashboards:</p> <ul> <li>Kubernetes Cluster Monitoring (8588) - Overview</li> <li>Kubernetes Pod Metrics (6417) - Pod details</li> <li>Kubernetes Deployment Metrics (8588) - Deployment health</li> </ul>"},{"location":"kubernetes/#operations","title":"\ud83d\udee0\ufe0f Operations","text":""},{"location":"kubernetes/#scaling-deployments","title":"Scaling Deployments","text":"<pre><code># Scale Prometheus to 2 replicas (for HA)\nkubectl scale deployment prometheus --replicas=2 -n monitoring\n\n# Check rollout status\nkubectl rollout status deployment/prometheus -n monitoring\n</code></pre>"},{"location":"kubernetes/#updating-configuration","title":"Updating Configuration","text":"<p>After modifying ConfigMaps:</p> <pre><code># Apply changes\nkubectl apply -f kubernetes/monitoring/01-prometheus-configmap.yaml\n\n# Restart deployment to pick up changes\nkubectl rollout restart deployment/prometheus -n monitoring\n</code></pre>"},{"location":"kubernetes/#viewing-logs","title":"Viewing Logs","text":"<pre><code># Prometheus logs\nkubectl logs -f deployment/prometheus -n monitoring\n\n# Grafana logs\nkubectl logs -f deployment/grafana -n monitoring\n\n# All pod logs in namespace\nkubectl logs -f --all-containers -l component=monitoring -n monitoring\n</code></pre>"},{"location":"kubernetes/#troubleshooting-pods","title":"Troubleshooting Pods","text":"<pre><code># Describe pod for events\nkubectl describe pod &lt;pod-name&gt; -n monitoring\n\n# Check pod status\nkubectl get pods -n monitoring -o wide\n\n# View recent events\nkubectl get events -n monitoring --sort-by='.lastTimestamp'\n</code></pre>"},{"location":"kubernetes/#performance-scaling","title":"\ud83d\udcc8 Performance &amp; Scaling","text":""},{"location":"kubernetes/#current-resource-usage","title":"Current Resource Usage","text":"<p>Measured on single-node K3s cluster:</p> Service CPU (avg) Memory (avg) Storage Prometheus 250m 800Mi 10Gi PVC Grafana 100m 350Mi 5Gi PVC Loki 200m 600Mi 20Gi PVC Tempo 200m 650Mi 20Gi PVC AlertManager 50m 150Mi 2Gi PVC"},{"location":"kubernetes/#storage-growth","title":"Storage Growth","text":"<p>With 15s scrape interval and current targets:</p> <ul> <li>Prometheus: ~500MB/day \u2192 7.5GB/15 days</li> <li>Loki: ~200MB/day \u2192 6GB/30 days</li> <li>Tempo: ~300MB/day \u2192 9GB/30 days</li> </ul> <p>Adjust PVC sizes based on your retention and volume needs.</p>"},{"location":"kubernetes/#security","title":"\ud83d\udd10 Security","text":""},{"location":"kubernetes/#rbac-configuration","title":"RBAC Configuration","text":"<p>Prometheus ServiceAccount has minimal required permissions:</p> <pre><code>rules:\n  - apiGroups: [\"\"]\n    resources: [nodes, services, endpoints, pods]\n    verbs: [get, list, watch]\n</code></pre>"},{"location":"kubernetes/#network-policies","title":"Network Policies","text":"<p>Services use ClusterIP (internal) by default. Only exposed via NodePort:</p> <ul> <li>Prometheus: 30090</li> <li>Grafana: 30300</li> <li>AlertManager: 30093</li> </ul>"},{"location":"kubernetes/#secret-management","title":"Secret Management","text":"<p>Grafana admin password can be set via Kubernetes Secret:</p> <pre><code>kubectl create secret generic grafana-admin \\\n  --from-literal=password='your-secure-password' \\\n  -n monitoring\n</code></pre>"},{"location":"kubernetes/#cleanup","title":"\ud83e\uddf9 Cleanup","text":""},{"location":"kubernetes/#remove-all-resources","title":"Remove All Resources","text":"<pre><code># Using Makefile\nmake k8s-clean\n\n# Or manually\nkubectl delete namespace monitoring\n</code></pre> <p>This removes:</p> <ul> <li>All deployments, services, and pods</li> <li>ConfigMaps</li> <li>PersistentVolumeClaims (data is deleted!)</li> <li>RBAC resources (ClusterRole, ClusterRoleBinding, ServiceAccount)</li> </ul>"},{"location":"kubernetes/#remove-only-workloads-keep-pvcs","title":"Remove Only Workloads (Keep PVCs)","text":"<pre><code>kubectl delete deployment --all -n monitoring\nkubectl delete service --all -n monitoring\n</code></pre> <p>PVCs remain, allowing you to redeploy without losing data.</p>"},{"location":"kubernetes/#next-steps","title":"\ud83d\udcda Next Steps","text":""},{"location":"kubernetes/#gitops-with-argocd","title":"GitOps with ArgoCD","text":"<p>Deploy ArgoCD to manage these manifests declaratively:</p> <pre><code># Install ArgoCD\nkubectl create namespace argocd\nkubectl apply -n argocd -f \\\n  https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml\n</code></pre>"},{"location":"kubernetes/#helm-charts","title":"Helm Charts","text":"<p>Convert manifests to Helm chart for easier management:</p> <pre><code>helm create homelab-monitoring\n# Move manifests into templates/\n</code></pre>"},{"location":"kubernetes/#service-mesh","title":"Service Mesh","text":"<p>Add Linkerd for mTLS and advanced traffic management:</p> <pre><code># Install Linkerd\nlinkerd install | kubectl apply -f -\nlinkerd check\n</code></pre>"},{"location":"kubernetes/#horizontal-pod-autoscaling","title":"Horizontal Pod Autoscaling","text":"<p>Enable HPA based on CPU/memory:</p> <pre><code>apiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: prometheus-hpa\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: prometheus\n  minReplicas: 1\n  maxReplicas: 3\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70\n</code></pre>"},{"location":"kubernetes/#skills-demonstrated","title":"\ud83c\udf93 Skills Demonstrated","text":"<p>This Kubernetes deployment showcases:</p> <ul> <li>\u2705 Kubernetes Architecture - Pods, Services, Deployments, PVCs</li> <li>\u2705 RBAC - ServiceAccounts, ClusterRoles, ClusterRoleBindings</li> <li>\u2705 Service Discovery - Kubernetes API integration</li> <li>\u2705 ConfigMap Management - Externalized configuration</li> <li>\u2705 Persistent Storage - PVC with local-path provisioner</li> <li>\u2705 Health Checks - Liveness and readiness probes</li> <li>\u2705 Resource Management - Requests, limits, and QoS</li> <li>\u2705 Declarative Management - GitOps-ready manifests</li> <li>\u2705 Production Patterns - HA considerations, scaling, monitoring</li> </ul>"},{"location":"kubernetes/#references","title":"\ud83d\udcd6 References","text":"<ul> <li>K3s Documentation</li> <li>Prometheus Operator</li> <li>Grafana on Kubernetes</li> <li>Kubernetes Monitoring Guide</li> </ul> <p>Built by Stephon Skipper | GitHub</p>"},{"location":"monitoring/","title":"Monitoring &amp; Observability","text":""},{"location":"monitoring/#overview","title":"Overview","text":"<p>This homelab includes a production-grade monitoring stack with Prometheus, Grafana, and AlertManager, providing real-time metrics, dashboards, and automated alerting with Slack integration for full infrastructure observability.</p>"},{"location":"monitoring/#stack-components","title":"Stack Components","text":""},{"location":"monitoring/#prometheus","title":"Prometheus","text":"<ul> <li>Time-series database for metrics collection</li> <li>Scrapes metrics from multiple exporters every 15 seconds</li> <li>15-day data retention</li> <li>HTTP API for querying metrics</li> <li>Alert rule evaluation with 15+ production-ready alerts</li> </ul>"},{"location":"monitoring/#grafana","title":"Grafana","text":"<ul> <li>Visualization platform for metrics dashboards</li> <li>Pre-configured Prometheus datasource</li> <li>Auto-provisioned dashboards</li> <li>Dark theme by default</li> <li>Supports importing from grafana.com</li> </ul>"},{"location":"monitoring/#alertmanager","title":"AlertManager","text":"<ul> <li>Alert routing and notification system</li> <li>Slack integration for critical/warning alerts</li> <li>Alert grouping and inhibition rules</li> <li>Silencing and acknowledgment support</li> <li>Production-ready alert receiver configuration</li> </ul>"},{"location":"monitoring/#node-exporter","title":"Node Exporter","text":"<ul> <li>Exports host system metrics: CPU, memory, disk I/O, network</li> <li>Runs in host network mode for accurate data collection</li> <li>Deployed to remote hosts via Ansible automation</li> </ul>"},{"location":"monitoring/#cadvisor","title":"cAdvisor","text":"<ul> <li>Container metrics for Docker</li> <li>Resource usage, performance characteristics, and running containers</li> <li>Built-in web UI</li> </ul>"},{"location":"monitoring/#quick-start","title":"Quick Start","text":"<pre><code># From repo root\nmake mon-up\n\n# Access services\n# Grafana:       http://localhost:3001\n# Prometheus:    http://localhost:9090\n# AlertManager:  http://localhost:9093\n# cAdvisor:      http://localhost:8080\n</code></pre> <p>Default Grafana credentials: <code>admin</code> / (set in <code>.env</code> - use Ansible Vault in production)</p>"},{"location":"monitoring/#architecture","title":"Architecture","text":"<pre><code>graph TB\n    subgraph \"Monitoring Stack\"\n        G[Grafana&lt;br/&gt;:3000]\n        P[Prometheus&lt;br/&gt;:9090]\n        NE[Node Exporter&lt;br/&gt;:9100]\n        CA[cAdvisor&lt;br/&gt;:8080]\n    end\n\n    subgraph \"Data Sources\"\n        Host[Host System&lt;br/&gt;CPU, RAM, Disk]\n        Docker[Docker&lt;br/&gt;Containers]\n    end\n\n    Host --&gt;|metrics| NE\n    Docker --&gt;|metrics| CA\n    NE --&gt;|scrape| P\n    CA --&gt;|scrape| P\n    P --&gt;|self-monitor| P\n    P --&gt;|query| G\n\n    style G fill:#f96,stroke:#333,stroke-width:2px\n    style P fill:#e94,stroke:#333,stroke-width:2px</code></pre>"},{"location":"monitoring/#configuration","title":"Configuration","text":""},{"location":"monitoring/#environment-variables","title":"Environment Variables","text":"<p>Create <code>.env</code> from <code>.env.example</code>:</p> <pre><code>cd docker/monitoring-stack\ncp .env.example .env\n</code></pre> <p>Key variables: - <code>GF_SECURITY_ADMIN_PASSWORD</code> - Grafana admin password (required) - <code>GRAFANA_PORT</code> - Grafana web port (default: 3000) - <code>PROMETHEUS_PORT</code> - Prometheus web port (default: 9090)</p>"},{"location":"monitoring/#prometheus-scrape-targets","title":"Prometheus Scrape Targets","text":"<p>Edit <code>prometheus/prometheus.yml</code> to add new scrape targets:</p> <pre><code>scrape_configs:\n  - job_name: my_service\n    static_configs:\n      - targets: [\"service:port\"]\n</code></pre> <p>Reload configuration: <pre><code>curl -X POST http://localhost:9090/-/reload\n</code></pre></p>"},{"location":"monitoring/#adding-grafana-dashboards","title":"Adding Grafana Dashboards","text":"<ol> <li>Manual import via Grafana UI:</li> <li>Navigate to Dashboards \u2192 Import</li> <li>Enter dashboard ID from grafana.com/dashboards</li> <li> <p>Select Prometheus datasource</p> </li> <li> <p>Auto-provision (recommended):    <pre><code># Download dashboard JSON\ncurl -o grafana/provisioning/dashboards/node-exporter-full.json \\\n  https://grafana.com/api/dashboards/1860/revisions/latest/download\n\n# Restart Grafana\ndocker compose restart grafana\n</code></pre></p> </li> </ol> <p>Recommended dashboards: - Node Exporter Full - System metrics - Docker &amp; System Monitoring - Container metrics - cAdvisor - Container resource usage</p>"},{"location":"monitoring/#monitoring-your-infrastructure","title":"Monitoring Your Infrastructure","text":""},{"location":"monitoring/#viewing-metrics","title":"Viewing Metrics","text":"<p>Prometheus Expression Browser: - Navigate to http://localhost:9090 - Use PromQL to query metrics:   <pre><code># CPU usage\nrate(node_cpu_seconds_total{mode=\"idle\"}[5m])\n\n# Memory usage\nnode_memory_MemAvailable_bytes / node_memory_MemTotal_bytes\n\n# Container CPU usage\nrate(container_cpu_usage_seconds_total[5m])\n</code></pre></p> <p>Grafana Dashboards: - Navigate to http://localhost:3000 - Explore \u2192 Dashboards - View pre-configured or imported dashboards</p>"},{"location":"monitoring/#setting-up-alerts","title":"Setting Up Alerts","text":"<p>Production-Ready Alert Rules Included:</p> <p>The monitoring stack comes with 15+ pre-configured alert rules in <code>prometheus/rules/alerts.yml</code>:</p> <p>System Alerts:</p> <ul> <li><code>NodeExporterDown</code> - Node exporter service failure (critical)</li> <li><code>HighCPUUsage</code> - CPU usage &gt;80% for 5 minutes (warning)</li> <li><code>HighMemoryUsage</code> - Memory usage &gt;90% for 5 minutes (critical)</li> <li><code>DiskSpaceLow</code> - Disk space &lt;15% (critical)</li> <li><code>DiskSpaceWarning</code> - Disk space &lt;25% (warning)</li> </ul> <p>Container Alerts:</p> <ul> <li><code>ContainerDown</code> - cAdvisor monitoring failure (critical)</li> <li><code>ContainerHighMemory</code> - Container using &gt;90% of memory limit (warning)</li> </ul> <p>Service Alerts:</p> <ul> <li><code>PrometheusDown</code> - Prometheus self-monitoring failure (critical)</li> <li><code>PrometheusTargetDown</code> - Any scrape target unreachable (warning)</li> <li><code>GrafanaDown</code> - Grafana dashboard unavailable (warning)</li> </ul> <p>Each alert includes:</p> <ul> <li>\u2705 Runbook commands for quick troubleshooting</li> <li>\u2705 Severity labels (critical/warning)</li> <li>\u2705 Clear descriptions of the issue</li> <li>\u2705 Threshold tuning based on best practices</li> </ul> <p>AlertManager Configuration:</p> <p>Configure Slack notifications in <code>alertmanager/alertmanager.yml</code>:</p> <pre><code>receivers:\n  - name: 'slack-critical'\n    slack_configs:\n      - api_url: 'YOUR_SLACK_WEBHOOK_URL'\n        channel: '#homelab-critical'\n</code></pre> <p>See <code>docker/monitoring-stack/alertmanager/README.md</code> for complete setup guide.</p> <p>Custom Alert Rules:</p> <p>Add your own rules in <code>prometheus/alert_rules.yml</code>:</p> <pre><code>groups:\n  - name: system_alerts\n    interval: 30s\n    rules:\n      - alert: HighCPUUsage\n        expr: 100 - (avg by (instance) (rate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100) &gt; 80\n        for: 5m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"High CPU usage detected\"\n</code></pre>"},{"location":"monitoring/#cicd-integration","title":"CI/CD Integration","text":"<p>The monitoring stack includes automated validation in GitHub Actions:</p> <pre><code>docker_compose:\n  runs-on: ubuntu-latest\n  steps:\n    - uses: actions/checkout@v4\n    - name: Validate monitoring docker-compose\n      run: docker compose -f docker/monitoring-stack/docker-compose.yml config\n</code></pre> <p>This ensures: - \u2705 Docker Compose syntax is valid - \u2705 Service definitions are correct - \u2705 Volume and network configurations are valid</p>"},{"location":"monitoring/#operations","title":"Operations","text":""},{"location":"monitoring/#startingstopping","title":"Starting/Stopping","text":"<pre><code># Start\nmake mon-up\n\n# Stop\nmake mon-down\n\n# View logs\nmake mon-logs\n</code></pre>"},{"location":"monitoring/#backup-restore","title":"Backup &amp; Restore","text":"<p>Backup Prometheus data: <pre><code>docker run --rm -v monitoring-stack_prometheus_data:/data \\\n  -v $(pwd):/backup alpine tar czf /backup/prometheus-backup.tar.gz -C /data .\n</code></pre></p> <p>Backup Grafana dashboards: <pre><code>docker run --rm -v monitoring-stack_grafana_data:/data \\\n  -v $(pwd):/backup alpine tar czf /backup/grafana-backup.tar.gz -C /data .\n</code></pre></p> <p>Restore: <pre><code>docker run --rm -v monitoring-stack_prometheus_data:/data \\\n  -v $(pwd):/backup alpine tar xzf /backup/prometheus-backup.tar.gz -C /data\n</code></pre></p>"},{"location":"monitoring/#troubleshooting","title":"Troubleshooting","text":"<p>Check service health: <pre><code>docker compose ps\n</code></pre></p> <p>View logs: <pre><code># All services\nmake mon-logs\n\n# Specific service\ndocker compose logs -f prometheus\n</code></pre></p> <p>Verify Prometheus targets: - Navigate to http://localhost:9090/targets - All targets should show \"UP\" status</p> <p>Reset all data: <pre><code>make mon-down\ndocker volume rm monitoring-stack_prometheus_data monitoring-stack_grafana_data\nmake mon-up\n</code></pre></p>"},{"location":"monitoring/#network-security","title":"Network Security","text":""},{"location":"monitoring/#firewall-configuration","title":"Firewall Configuration","text":"<p>If accessing from remote machines (Fedora/RHEL):</p> <pre><code>sudo firewall-cmd --add-port=3000/tcp --permanent  # Grafana\nsudo firewall-cmd --add-port=9090/tcp --permanent  # Prometheus\nsudo firewall-cmd --reload\n</code></pre>"},{"location":"monitoring/#production-considerations","title":"Production Considerations","text":"<p>For production deployments:</p> <ol> <li>Use HTTPS: Place Nginx reverse proxy in front</li> <li>Authentication: Enable Grafana LDAP/OAuth</li> <li>Network isolation: Use Docker networks properly</li> <li>Secrets management: Use Docker secrets instead of <code>.env</code></li> <li>Persistent storage: Use bind mounts with backup strategy</li> <li>Alerting: Configure Alertmanager for notifications</li> </ol>"},{"location":"monitoring/#extending-the-stack","title":"Extending the Stack","text":""},{"location":"monitoring/#adding-remote-targets","title":"Adding Remote Targets","text":"<p>To monitor remote hosts, install Node Exporter as a systemd service:</p> <pre><code># See ansible/roles/monitoring role (future addition)\n# Will deploy node_exporter to remote hosts via Ansible\n</code></pre>"},{"location":"monitoring/#integration-with-other-services","title":"Integration with Other Services","text":"<p>Add scrape configs for: - Nginx: nginx-prometheus-exporter - PostgreSQL: postgres_exporter - Redis: redis_exporter - Custom apps: Prometheus client libraries</p> <p>Example: <pre><code>scrape_configs:\n  - job_name: nginx\n    static_configs:\n      - targets: [\"nginx-exporter:9113\"]\n</code></pre></p>"},{"location":"monitoring/#deploying-node-exporter-to-remote-hosts","title":"Deploying Node Exporter to Remote Hosts","text":"<p>Use the included Ansible role to automatically deploy node_exporter:</p> <pre><code># Deploy to all managed hosts\ncd ansible\nansible-playbook playbooks/deploy-monitoring.yml\n\n# Generate Prometheus targets from inventory\npython3 ../scripts/generate_prometheus_targets.py inventories/hosts\n</code></pre> <p>This installs node_exporter as a systemd service with:</p> <ul> <li>\u2705 Automatic firewall configuration</li> <li>\u2705 Security hardening</li> <li>\u2705 Health check verification</li> </ul> <p>See the monitoring role on GitHub for details.</p>"},{"location":"monitoring/#references","title":"References","text":"<ul> <li>Prometheus Documentation</li> <li>Grafana Documentation</li> <li>Node Exporter</li> <li>cAdvisor</li> <li>PromQL Basics</li> </ul>"},{"location":"monitoring/#next-steps","title":"Next Steps","text":"<ul> <li> Production AlertManager with Slack \u2705</li> <li> 15+ Alert rules with runbooks \u2705</li> <li> Deploy node_exporter to remote hosts via Ansible \u2705</li> <li> Secrets management with Ansible Vault \u2705</li> <li> Automated backup/restore scripts \u2705</li> <li> Import pre-built Grafana dashboards (Node Exporter Full, Docker)</li> <li> Configure Nginx reverse proxy with SSL</li> <li> Log aggregation with Loki + Promtail</li> <li> Distributed tracing with Tempo</li> </ul>"},{"location":"packer/","title":"Packer Automated Image Builds","text":"<p>Automated AMI builds with comprehensive security hardening, monitoring tools, and Docker using HashiCorp Packer.</p>"},{"location":"packer/#overview","title":"\ud83c\udfaf Overview","text":"<p>This implementation demonstrates immutable infrastructure through automated machine image builds. Rather than provisioning instances with user_data scripts, we pre-bake hardened AMIs with all required tools and configurations.</p>"},{"location":"packer/#benefits","title":"Benefits","text":"<ul> <li>\u2705 Faster Boot Times - No runtime provisioning needed</li> <li>\u2705 Consistency - Identical configuration across all instances</li> <li>\u2705 Security - Hardening applied at image level</li> <li>\u2705 Version Control - Timestamped AMIs enable rollback</li> <li>\u2705 Immutability - Infrastructure as code for machine images</li> </ul>"},{"location":"packer/#architecture","title":"\ud83c\udfd7\ufe0f Architecture","text":"<p>The build process follows a multi-stage provisioning workflow:</p> <pre><code>graph LR\n    A[Source AMI&lt;br/&gt;Ubuntu 22.04] --&gt; B[System Update]\n    B --&gt; C[Install Packages&lt;br/&gt;AWS CLI, SSM, CW]\n    C --&gt; D[Security Hardening&lt;br/&gt;SSH, Firewall, IDS]\n    D --&gt; E[Install Monitoring&lt;br/&gt;Node Exporter, Promtail]\n    E --&gt; F[Install Docker&lt;br/&gt;Engine + Compose]\n    F --&gt; G[Cleanup&lt;br/&gt;Logs, Keys, Temp]\n    G --&gt; H[Hardened AMI&lt;br/&gt;Encrypted, IMDSv2]</code></pre>"},{"location":"packer/#whats-included","title":"\ud83d\udce6 What's Included","text":""},{"location":"packer/#base-ubuntu-2204-lts","title":"Base: Ubuntu 22.04 LTS","text":"<p>Official Canonical AMI with: - Latest security patches - EBS encryption enabled - IMDSv2 enforced</p>"},{"location":"packer/#security-hardening","title":"Security Hardening","text":"<p>SSH Configuration: - Root login disabled - Password authentication disabled - Key-only authentication (PubkeyAuthentication) - Protocol 2 only - Connection limits (MaxAuthTries: 3, MaxSessions: 2) - Client timeouts configured</p> <p>Firewall (UFW): - Default deny incoming traffic - Default allow outgoing traffic - SSH port 22 allowed - Enabled and active on boot</p> <p>fail2ban: - SSH brute-force protection - 5 attempts allowed in 10 minutes - 1-hour ban time - Configured and running</p> <p>Kernel Hardening (sysctl): - IP forwarding disabled - SYN flood protection enabled - ICMP redirects ignored - Source routing disabled - Martian packet logging - Reverse path filtering enabled</p> <p>Additional Security: - ClamAV: Antivirus with automatic signature updates - AIDE: Advanced Intrusion Detection Environment - Unattended Upgrades: Automatic security patches - Secure file permissions (/etc/passwd, /etc/shadow, grub)</p>"},{"location":"packer/#aws-integration","title":"AWS Integration","text":"<ul> <li>AWS CLI v2: Latest command-line interface</li> <li>SSM Agent: Remote management without SSH</li> <li>CloudWatch Agent: Metrics and log shipping to CloudWatch</li> </ul>"},{"location":"packer/#monitoring-stack","title":"Monitoring Stack","text":"<ul> <li>Prometheus Node Exporter: </li> <li>System metrics (CPU, RAM, disk, network)</li> <li>Systemd integration</li> <li>Process collector enabled</li> <li> <p>Exposed on port 9100</p> </li> <li> <p>Promtail:</p> </li> <li>Log shipping to Loki</li> <li>Configured for /var/log/*log</li> <li>Systemd service enabled</li> <li>Port 9080</li> </ul>"},{"location":"packer/#container-runtime","title":"Container Runtime","text":"<ul> <li>Docker Engine: Latest stable from official repository</li> <li>Docker Compose v2: Plugin and standalone binary</li> <li>Daemon Hardening:</li> <li>JSON file logging with rotation (10MB max, 3 files)</li> <li>Live restore enabled</li> <li>Metrics endpoint (127.0.0.1:9323)</li> <li>Userland proxy disabled for performance</li> </ul>"},{"location":"packer/#developer-tools","title":"Developer Tools","text":"<p>Essential CLI utilities: - curl, wget, git, vim, htop - jq (JSON processor) - Python 3 with pip - Build essentials (gcc, make) - net-tools, unzip, ca-certificates</p>"},{"location":"packer/#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"packer/#prerequisites","title":"Prerequisites","text":"<pre><code># Install Packer\nbrew install packer  # macOS\n# or use our build.sh script (auto-installs)\n\n# Configure AWS credentials\nexport AWS_ACCESS_KEY_ID=\"your-key\"\nexport AWS_SECRET_ACCESS_KEY=\"your-secret\"\nexport AWS_DEFAULT_REGION=\"us-east-1\"\n</code></pre>"},{"location":"packer/#build-process","title":"Build Process","text":"<pre><code>cd packer\n\n# Copy variables template\ncp variables.pkrvars.hcl.example variables.auto.pkrvars.hcl\n\n# Edit configuration\nvim variables.auto.pkrvars.hcl\n\n# Initialize Packer plugins\npacker init aws-ubuntu.pkr.hcl\n\n# Validate template\npacker validate -var-file=variables.auto.pkrvars.hcl aws-ubuntu.pkr.hcl\n\n# Build AMI (~15 minutes)\npacker build -var-file=variables.auto.pkrvars.hcl aws-ubuntu.pkr.hcl\n</code></pre>"},{"location":"packer/#makefile-commands","title":"Makefile Commands","text":"<pre><code>make packer-init      # Initialize plugins\nmake packer-validate  # Validate template\nmake packer-build     # Build AMI (requires confirmation)\nmake packer-clean     # Clean artifacts\n</code></pre>"},{"location":"packer/#configuration","title":"\u2699\ufe0f Configuration","text":""},{"location":"packer/#variables","title":"Variables","text":"<p><code>variables.auto.pkrvars.hcl</code>:</p> <pre><code>ami_name        = \"homelab-ubuntu-22.04\"\nami_description = \"Ubuntu 22.04 with security hardening\"\nregion          = \"us-east-1\"\ninstance_type   = \"t3.micro\"\n\n# Optional: Build in specific VPC/Subnet\n# vpc_id    = \"vpc-xxxxx\"\n# subnet_id = \"subnet-xxxxx\"\n\nssh_username = \"ubuntu\"\n</code></pre>"},{"location":"packer/#customization","title":"Customization","text":"<p>Modify provisioning scripts in <code>packer/scripts/</code>:</p> <ul> <li>Add packages: <code>02-install-packages.sh</code></li> <li>Custom security: <code>03-security-hardening.sh</code></li> <li>Additional monitoring: <code>04-install-monitoring.sh</code></li> <li>Remove Docker: Comment out in template</li> </ul>"},{"location":"packer/#terraform-integration","title":"\ud83d\udd17 Terraform Integration","text":""},{"location":"packer/#use-custom-ami","title":"Use Custom AMI","text":"<pre><code># Data source to find latest AMI\ndata \"aws_ami\" \"homelab_ubuntu\" {\n  most_recent = true\n  owners      = [\"self\"]\n\n  filter {\n    name   = \"name\"\n    values = [\"homelab-ubuntu-22.04-*\"]\n  }\n\n  filter {\n    name   = \"state\"\n    values = [\"available\"]\n  }\n}\n\n# Launch instance from custom AMI\nresource \"aws_instance\" \"server\" {\n  ami           = data.aws_ami.homelab_ubuntu.id\n  instance_type = \"t3.micro\"\n  key_name      = var.key_name\n\n  # No user_data needed - everything pre-installed!\n\n  tags = {\n    Name = \"Hardened Ubuntu Server\"\n  }\n}\n</code></pre>"},{"location":"packer/#benefits_1","title":"Benefits","text":"<ul> <li>Faster Launch: No provisioning scripts to run</li> <li>Consistency: Same configuration every time</li> <li>Reliability: Pre-tested image</li> <li>Rollback: Easy to revert to previous AMI version</li> </ul>"},{"location":"packer/#build-output","title":"\ud83d\udcca Build Output","text":"<pre><code>==&gt; amazon-ebs.ubuntu: Creating temporary keypair\n==&gt; amazon-ebs.ubuntu: Launching source instance...\n==&gt; amazon-ebs.ubuntu: Waiting for instance to become ready...\n==&gt; amazon-ebs.ubuntu: Connected to SSH!\n==&gt; amazon-ebs.ubuntu: Provisioning with shell script: 01-system-update.sh\n==&gt; amazon-ebs.ubuntu: Provisioning with shell script: 02-install-packages.sh\n==&gt; amazon-ebs.ubuntu: Provisioning with shell script: 03-security-hardening.sh\n==&gt; amazon-ebs.ubuntu: Provisioning with shell script: 04-install-monitoring.sh\n==&gt; amazon-ebs.ubuntu: Provisioning with shell script: 05-install-docker.sh\n==&gt; amazon-ebs.ubuntu: Provisioning with shell script: 99-cleanup.sh\n==&gt; amazon-ebs.ubuntu: Stopping source instance...\n==&gt; amazon-ebs.ubuntu: Creating AMI...\n==&gt; amazon-ebs.ubuntu: AMI: ami-0123456789abcdef0\n==&gt; amazon-ebs.ubuntu: Terminating source instance...\n==&gt; amazon-ebs.ubuntu: Deleting temporary keypair...\n\nBuild finished. The artifacts of successful builds are:\n--&gt; amazon-ebs.ubuntu: AMIs were created:\nus-east-1: ami-0123456789abcdef0\n</code></pre>"},{"location":"packer/#validation","title":"\u2705 Validation","text":""},{"location":"packer/#test-instance","title":"Test Instance","text":"<pre><code># Launch from custom AMI\naws ec2 run-instances \\\n  --image-id ami-0123456789abcdef0 \\\n  --instance-type t3.micro \\\n  --key-name your-key\n\n# Connect via SSM (no SSH key needed!)\naws ssm start-session --target i-xxxxx\n\n# Or traditional SSH\nssh ubuntu@&lt;public-ip&gt;\n</code></pre>"},{"location":"packer/#verify-components","title":"Verify Components","text":"<pre><code># Security\nsudo ufw status\nsudo fail2ban-client status\nfreshclam --version\n\n# Monitoring\nsystemctl status node_exporter\nsystemctl status promtail\ncurl localhost:9100/metrics\n\n# Docker\ndocker --version\ndocker compose version\n\n# AWS Tools\naws --version\n/snap/bin/amazon-ssm-agent --version\n</code></pre>"},{"location":"packer/#skills-demonstrated","title":"\ud83c\udf93 Skills Demonstrated","text":"<ul> <li>\u2705 Packer: HCL2 templates, multi-stage builds</li> <li>\u2705 Security: SSH hardening, firewall, IDS, antivirus</li> <li>\u2705 Automation: Shell scripting, systemd services</li> <li>\u2705 AWS: CLI, SSM, CloudWatch, IMDSv2, encryption</li> <li>\u2705 Monitoring: Prometheus exporters, Loki integration</li> <li>\u2705 Containers: Docker installation and hardening</li> <li>\u2705 Immutable Infrastructure: Image-based deployments</li> <li>\u2705 DevOps Best Practices: Version control, repeatability</li> </ul>"},{"location":"packer/#resources","title":"\ud83d\udcda Resources","text":"<ul> <li>Full template: <code>packer/aws-ubuntu.pkr.hcl</code></li> <li>Provisioning scripts: <code>packer/scripts/</code></li> <li>README: <code>packer/README.md</code></li> <li>Packer Documentation</li> <li>Amazon EBS Builder</li> </ul> <p>Built by Stephon Skipper | GitHub</p>"},{"location":"pipelines/","title":"Pipelines","text":"<p>Flow: lint \u2192 plan \u2192 approve \u2192 apply \u2192 configure \u2192 smoke</p> <ul> <li>Lint: pre-commit (TFLint, Checkov, Ansible-lint, Hadolint)</li> <li>Plan/Apply: Terraform with remote backend (planned)</li> <li>Configure: Ansible targets AWS/Proxmox from TF outputs</li> <li>Deploy: Reverse proxy + sample app</li> <li>Smoke: curl healthchecks (non-200 fails the job)</li> </ul>"},{"location":"projects/","title":"Projects","text":""},{"location":"projects/#quick-links","title":"\ud83d\udc47 Quick links","text":"<ul> <li>Terraform Module: <code>terraform/modules/ec2_minimal/</code></li> <li>AWS Example: <code>terraform/aws-ec2/</code></li> <li>Ansible Monitoring Role: <code>ansible/roles/monitoring/</code></li> <li>Ansible Security Role: <code>ansible/roles/secure/</code></li> <li>Monitoring Stack: <code>docker/monitoring-stack/</code></li> <li>Reverse Proxy Demo: <code>docker/reverse-proxy/</code></li> </ul>"},{"location":"projects/#monitoring-stack-prometheus-grafana","title":"Monitoring Stack: Prometheus + Grafana","text":"<p>What it does</p> <ul> <li>Full observability stack with Prometheus, Grafana, Node Exporter, and cAdvisor</li> <li>Auto-provisioned Grafana datasources and dashboards</li> <li>SELinux/Fedora compatible configurations</li> <li>Makefile commands for easy management</li> </ul> <p>Try it <pre><code>make mon-up\n# Access Grafana at http://localhost:3001\n</code></pre></p>"},{"location":"projects/#ansible-monitoring-role","title":"Ansible: Monitoring Role","text":"<p>What it does</p> <ul> <li>Deploys Prometheus Node Exporter to remote hosts</li> <li>Installs as systemd service with security hardening</li> <li>Auto-configures firewall (firewalld/ufw)</li> <li>Idempotent deployment with version management</li> </ul> <p>Try it <pre><code>cd ansible\nansible-playbook playbooks/deploy-monitoring.yml\n</code></pre></p>"},{"location":"projects/#terraform-ec2-minimal","title":"Terraform: EC2 minimal","text":"<p>What it does</p> <ul> <li>IMDSv2 required, EBS optimized, encrypted root volume  </li> <li>Optional SSM instance profile (zero-SSH)  </li> <li>Outputs public IP / instance ID</li> </ul> <p>Try it <pre><code>cd terraform/aws-ec2\nterraform init -backend=false\nterraform plan -var key_name=MY_KEY\n</code></pre></p>"},{"location":"reverse-proxy/","title":"Docker &amp; Reverse Proxy","text":"<p>This repository includes a lightweight container platform running internal services behind a reverse proxy.</p>"},{"location":"reverse-proxy/#core-components","title":"\u2705 Core Components","text":"Component Purpose Docker Engine / Compose Container runtime &amp; orchestration Nginx Reverse Proxy Front door to services whoami test service Demo backend to validate routing Health checks Validate uptime + internal routing"},{"location":"reverse-proxy/#folder-structure","title":"\ud83e\uddf1 Folder Structure","text":"<p>```bash docker/reverse-proxy/ \u251c\u2500 docker-compose.yml \u2514\u2500 nginx/    \u2514\u2500 conf.d/       \u2514\u2500 whoami.conf</p> <p>flowchart LR User[Client] --&gt; Proxy[Nginx Reverse Proxy] Proxy --&gt; whoami[Test Container] Proxy --&gt; OtherApps[Future Apps (Grafana, Wazuh, etc)]</p> <p>\ud83d\udd10 Reverse Proxy Config (Nginx) server {   listen 80;   server_name _;</p> <p>location / {     proxy_pass http://whoami:80;     proxy_set_header Host $host;     proxy_set_header X-Real-IP $remote_addr;     proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;     proxy_set_header X-Forwarded-Proto $scheme;   } }</p> <p>\ud83d\ude80 Deployment</p> <p>cd docker/reverse-proxy docker-compose up -d</p> <p>\ud83e\uddea Smoke Test</p> <p>curl -sI http://localhost:8080 | head -n 1 curl http://localhost:8080</p> <p>\u2705 Live Proof</p> <p>See docs/images/ for screenshot</p>"},{"location":"security/","title":"Container Security Scanning with Trivy","text":"<p>This repository uses Trivy to scan Docker images for security vulnerabilities as part of the CI/CD pipeline.</p>"},{"location":"security/#what-is-trivy","title":"What is Trivy?","text":"<p>Trivy is a comprehensive security scanner for: - Container images (Docker, OCI) - Filesystems and Git repositories - Vulnerabilities (CVE database) - Misconfigurations (Kubernetes, Docker, Terraform) - Secrets and sensitive information</p>"},{"location":"security/#scanning-strategy","title":"Scanning Strategy","text":""},{"location":"security/#cicd-integration","title":"CI/CD Integration","text":"<p>Every push triggers automatic vulnerability scans in GitHub Actions for:</p> <ul> <li>Prometheus (<code>prom/prometheus:latest</code>)</li> <li>Grafana (<code>grafana/grafana:latest</code>)</li> <li>AlertManager (<code>prom/alertmanager:latest</code>)</li> <li>Node Exporter (<code>prom/node-exporter:latest</code>)</li> <li>cAdvisor (<code>gcr.io/cadvisor/cadvisor:latest</code>)</li> </ul> <p>Scans focus on HIGH and CRITICAL severity vulnerabilities.</p>"},{"location":"security/#local-scanning","title":"Local Scanning","text":"<p>Run security scans locally before pushing:</p> <pre><code># Using Makefile\nmake security-scan\n\n# Or directly\n./scripts/trivy-scan.sh\n</code></pre>"},{"location":"security/#installation","title":"Installation","text":""},{"location":"security/#fedorarhel","title":"Fedora/RHEL","text":"<pre><code>sudo dnf install -y trivy\n</code></pre>"},{"location":"security/#ubuntudebian","title":"Ubuntu/Debian","text":"<pre><code># Add repository\nwget -qO - https://aquasecurity.github.io/trivy-repo/deb/public.key | gpg --dearmor | sudo tee /usr/share/keyrings/trivy.gpg &gt; /dev/null\necho \"deb [signed-by=/usr/share/keyrings/trivy.gpg] https://aquasecurity.github.io/trivy-repo/deb $(lsb_release -sc) main\" | sudo tee -a /etc/apt/sources.list.d/trivy.list\n\n# Install\nsudo apt-get update\nsudo apt-get install trivy\n</code></pre>"},{"location":"security/#macos","title":"macOS","text":"<pre><code>brew install trivy\n</code></pre>"},{"location":"security/#usage","title":"Usage","text":""},{"location":"security/#scan-a-single-image","title":"Scan a Single Image","text":"<pre><code># Basic scan\ntrivy image grafana/grafana:latest\n\n# Only high and critical vulnerabilities\ntrivy image --severity HIGH,CRITICAL grafana/grafana:latest\n\n# Output as JSON\ntrivy image --format json --output results.json grafana/grafana:latest\n\n# Scan and exit with error if vulnerabilities found\ntrivy image --exit-code 1 --severity CRITICAL grafana/grafana:latest\n</code></pre>"},{"location":"security/#scan-docker-compose-stack","title":"Scan Docker Compose Stack","text":"<pre><code># Extract images from docker-compose.yml\ndocker compose -f docker/monitoring-stack/docker-compose.yml config --images | xargs -I {} trivy image {}\n</code></pre>"},{"location":"security/#scan-specific-vulnerability-types","title":"Scan Specific Vulnerability Types","text":"<pre><code># OS packages only\ntrivy image --vuln-type os grafana/grafana:latest\n\n# Application dependencies only  \ntrivy image --vuln-type library grafana/grafana:latest\n\n# Both\ntrivy image --vuln-type os,library grafana/grafana:latest\n</code></pre>"},{"location":"security/#understanding-results","title":"Understanding Results","text":""},{"location":"security/#severity-levels","title":"Severity Levels","text":"<ul> <li>CRITICAL: Immediate action required - exploitable vulnerability</li> <li>HIGH: Patch soon - significant security risk</li> <li>MEDIUM: Schedule patching - moderate risk</li> <li>LOW: Informational - minimal risk</li> <li>UNKNOWN: Not yet assessed by CVE database</li> </ul>"},{"location":"security/#sample-output","title":"Sample Output","text":"<pre><code>grafana/grafana:latest (debian 12.1)\n\nTotal: 45 (HIGH: 12, CRITICAL: 3)\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502     Library      \u2502 Vulnerability  \u2502 Severity \u2502 Installed Version \u2502 Fixed Version \u2502        Title         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 openssl          \u2502 CVE-2024-1234  \u2502 CRITICAL \u2502 1.1.1n            \u2502 1.1.1p        \u2502 OpenSSL security...  \u2502\n\u2502 libcurl          \u2502 CVE-2024-5678  \u2502 HIGH     \u2502 7.68.0            \u2502 7.74.0        \u2502 curl security flaw   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"security/#remediation-workflow","title":"Remediation Workflow","text":""},{"location":"security/#1-review-scan-results","title":"1. Review Scan Results","text":"<pre><code># Generate detailed report\ntrivy image --format json --output scan-report.json grafana/grafana:latest\n\n# View critical vulnerabilities only\ntrivy image --severity CRITICAL grafana/grafana:latest\n</code></pre>"},{"location":"security/#2-check-for-updates","title":"2. Check for Updates","text":"<pre><code># Pull latest image\ndocker pull grafana/grafana:latest\n\n# Rescan\ntrivy image grafana/grafana:latest\n</code></pre>"},{"location":"security/#3-pin-specific-versions","title":"3. Pin Specific Versions","text":"<p>If <code>latest</code> has critical vulnerabilities, pin to a specific version:</p> <pre><code># docker-compose.yml\nservices:\n  grafana:\n    image: grafana/grafana:10.2.3  # Pinned version instead of :latest\n</code></pre>"},{"location":"security/#4-track-in-issues","title":"4. Track in Issues","text":"<p>For unfixed vulnerabilities:</p> <ol> <li>Check if upstream project has a fix</li> <li>Monitor CVE database for patches</li> <li>Consider temporary workarounds</li> <li>Document accepted risks</li> </ol>"},{"location":"security/#cicd-configuration","title":"CI/CD Configuration","text":""},{"location":"security/#github-actions-workflow","title":"GitHub Actions Workflow","text":"<pre><code>security_scan:\n  runs-on: ubuntu-latest\n  permissions:\n    contents: read\n    security-events: write\n  steps:\n    - uses: actions/checkout@v4\n\n    - name: Run Trivy Scanner\n      uses: aquasecurity/trivy-action@master\n      with:\n        image-ref: 'grafana/grafana:latest'\n        format: 'table'\n        exit-code: '0'  # Change to '1' to fail pipeline on vulnerabilities\n        severity: 'CRITICAL,HIGH'\n</code></pre>"},{"location":"security/#exit-code-strategy","title":"Exit Code Strategy","text":"<ul> <li><code>exit-code: 0</code> - Informational (doesn't fail build)</li> <li><code>exit-code: 1</code> - Fail build if vulnerabilities found (strict mode)</li> </ul> <p>Current Setup: Informational mode (<code>0</code>) for visibility without blocking deployments.</p> <p>Production Recommendation: Use <code>exit-code: 1</code> for production branches.</p>"},{"location":"security/#automation","title":"Automation","text":""},{"location":"security/#pre-commit-hook","title":"Pre-commit Hook","text":"<p>Add to <code>.pre-commit-config.yaml</code>:</p> <pre><code>- repo: local\n  hooks:\n    - id: trivy-scan\n      name: Trivy Security Scan\n      entry: ./scripts/trivy-scan.sh\n      language: script\n      pass_filenames: false\n</code></pre>"},{"location":"security/#scheduled-scans","title":"Scheduled Scans","text":"<p>Add to GitHub Actions for weekly scans:</p> <pre><code>on:\n  schedule:\n    - cron: '0 0 * * 0'  # Weekly on Sunday\n</code></pre>"},{"location":"security/#best-practices","title":"Best Practices","text":""},{"location":"security/#do","title":"\u2705 DO","text":"<ul> <li>Scan images regularly (weekly minimum)</li> <li>Pin image versions in production</li> <li>Monitor upstream security advisories</li> <li>Update base images promptly for critical CVEs</li> <li>Use minimal base images (alpine, distroless)</li> <li>Scan before and after deployment</li> <li>Document accepted risks for unfixed vulnerabilities</li> </ul>"},{"location":"security/#dont","title":"\u274c DON'T","text":"<ul> <li>Use <code>:latest</code> tags in production</li> <li>Ignore CRITICAL vulnerabilities</li> <li>Assume vendor images are secure</li> <li>Skip scans for \"trusted\" images</li> <li>Deploy without knowing vulnerability status</li> </ul>"},{"location":"security/#advanced-usage","title":"Advanced Usage","text":""},{"location":"security/#scan-local-dockerfile","title":"Scan Local Dockerfile","text":"<pre><code>trivy config Dockerfile\n</code></pre>"},{"location":"security/#scan-filesystem","title":"Scan Filesystem","text":"<pre><code>trivy fs /path/to/directory\n</code></pre>"},{"location":"security/#scan-kubernetes-manifests","title":"Scan Kubernetes Manifests","text":"<pre><code>trivy config k8s-deployment.yaml\n</code></pre>"},{"location":"security/#scan-terraform-code","title":"Scan Terraform Code","text":"<pre><code>trivy config terraform/\n</code></pre>"},{"location":"security/#custom-policy","title":"Custom Policy","text":"<p>Create <code>.trivyignore</code> to suppress specific CVEs:</p> <pre><code># .trivyignore\n# Suppress known false positive\nCVE-2024-1234\n\n# Suppress until fix available (document why)\nCVE-2024-5678  # No fix available, mitigated by network policy\n</code></pre>"},{"location":"security/#integration-with-security-tools","title":"Integration with Security Tools","text":""},{"location":"security/#sarif-output-for-github-security-tab","title":"SARIF Output for GitHub Security Tab","text":"<pre><code>- name: Run Trivy Scanner\n  uses: aquasecurity/trivy-action@master\n  with:\n    image-ref: 'grafana/grafana:latest'\n    format: 'sarif'\n    output: 'trivy-results.sarif'\n\n- name: Upload to GitHub Security\n  uses: github/codeql-action/upload-sarif@v2\n  with:\n    sarif_file: 'trivy-results.sarif'\n</code></pre>"},{"location":"security/#slack-notifications","title":"Slack Notifications","text":"<pre><code># Scan and send results to Slack\ntrivy image grafana/grafana:latest --format json | \\\n  jq -r '.Results[] | select(.Vulnerabilities != null) | .Vulnerabilities[] | select(.Severity == \"CRITICAL\")' | \\\n  wc -l | \\\n  xargs -I {} curl -X POST $SLACK_WEBHOOK_URL -d '{\"text\":\"Found {} critical vulnerabilities\"}'\n</code></pre>"},{"location":"security/#metrics-and-reporting","title":"Metrics and Reporting","text":""},{"location":"security/#track-vulnerability-trends","title":"Track Vulnerability Trends","text":"<pre><code># Generate monthly reports\nmkdir -p security-reports/$(date +%Y-%m)\ntrivy image --format json \\\n  --output security-reports/$(date +%Y-%m)/scan-$(date +%Y-%m-%d).json \\\n  grafana/grafana:latest\n</code></pre>"},{"location":"security/#dashboard-metrics","title":"Dashboard Metrics","text":"<p>Track in Prometheus:</p> <ul> <li>Number of images scanned</li> <li>Critical vulnerabilities count</li> <li>Mean time to remediation (MTTR)</li> <li>Scan frequency</li> </ul>"},{"location":"security/#resources","title":"Resources","text":"<ul> <li>Trivy Documentation</li> <li>Trivy GitHub Repository</li> <li>CVE Database</li> <li>National Vulnerability Database</li> <li>Trivy Operator for Kubernetes</li> </ul>"},{"location":"security/#troubleshooting","title":"Troubleshooting","text":""},{"location":"security/#scan-taking-too-long","title":"Scan Taking Too Long","text":"<pre><code># Skip database update if recent\ntrivy image --skip-db-update grafana/grafana:latest\n\n# Use cache\ntrivy image --cache-dir ~/.cache/trivy grafana/grafana:latest\n</code></pre>"},{"location":"security/#database-update-fails","title":"Database Update Fails","text":"<pre><code># Manual database update\ntrivy image --download-db-only\n\n# Clear cache and retry\ntrivy image --clear-cache\n</code></pre>"},{"location":"security/#false-positives","title":"False Positives","text":"<ol> <li>Verify vulnerability applies to your usage</li> <li>Check if already patched in latest version</li> <li>Add to <code>.trivyignore</code> with documentation</li> <li>Report to Trivy if incorrect</li> </ol>"},{"location":"security/#security-scanning-checklist","title":"Security Scanning Checklist","text":"<ul> <li> Trivy installed locally</li> <li> CI/CD integration configured</li> <li> All images scanned before deployment</li> <li> Critical vulnerabilities documented</li> <li> <code>.trivyignore</code> file maintained</li> <li> Scan results reviewed weekly</li> <li> Update schedule established</li> <li> Team notified of critical findings</li> <li> Remediation tracked in issues</li> </ul> <p>Remember: Security scanning is ongoing, not one-time. Regularly update and rescan images as new vulnerabilities are discovered.</p>"},{"location":"terraform/","title":"Terraform Infrastructure","text":"<p>Infrastructure as Code (IaC) for provisioning cloud resources on AWS and Proxmox using HashiCorp Terraform.</p>"},{"location":"terraform/#overview","title":"\ud83c\udfaf Overview","text":"<p>This implementation demonstrates production-ready Terraform practices including:</p> <ul> <li>\u2705 Reusable Modules - DRY principle with ec2_minimal module</li> <li>\u2705 Built-in Testing - Terraform test framework for validation</li> <li>\u2705 Security Hardening - IMDSv2, encryption, no hardcoded credentials</li> <li>\u2705 Multi-Environment - Workspaces for dev/staging/prod</li> <li>\u2705 State Management - Remote state with S3 backend support</li> <li>\u2705 CI/CD Integration - Automated validation in pipelines</li> </ul>"},{"location":"terraform/#architecture","title":"\ud83c\udfd7\ufe0f Architecture","text":"<pre><code>graph TB\n    subgraph \"Developer Workflow\"\n        DEV[Developer] --&gt; CODE[Write Terraform]\n        CODE --&gt; LOCAL[Local Validation]\n    end\n\n    subgraph \"CI/CD Pipeline\"\n        LOCAL --&gt; GIT[Git Push]\n        GIT --&gt; CI[GitHub Actions]\n        CI --&gt; FMT[terraform fmt]\n        CI --&gt; VAL[terraform validate]\n        CI --&gt; TEST[terraform test]\n        CI --&gt; SEC[Checkov Security Scan]\n    end\n\n    subgraph \"Terraform Deployment\"\n        SEC --&gt; PLAN[terraform plan]\n        PLAN --&gt; APPROVE[Manual Approval]\n        APPROVE --&gt; APPLY[terraform apply]\n    end\n\n    subgraph \"Cloud Resources\"\n        APPLY --&gt; AWS[AWS EC2 Instance]\n        APPLY --&gt; PROXMOX[Proxmox VMs]\n    end\n\n    AWS --&gt; ANSIBLE[Ansible Bootstrap]\n    PROXMOX --&gt; ANSIBLE</code></pre>"},{"location":"terraform/#components-managed","title":"\u2705 Components Managed","text":"Platform Resources Notes AWS EC2 Instance, Security Groups, EBS Volumes IMDSv2 enforced, encrypted volumes, SSM enabled Proxmox Virtual Machines Terraform provider integration with local homelab"},{"location":"terraform/#repository-structure","title":"\ufffd Repository Structure","text":"<pre><code>terraform/\n\u251c\u2500\u2500 aws-ec2/                    # AWS EC2 deployment\n\u2502   \u251c\u2500\u2500 main.tf                 # EC2 instance configuration\n\u2502   \u251c\u2500\u2500 variables.tf            # Input variables\n\u2502   \u251c\u2500\u2500 outputs.tf              # Output values\n\u2502   \u2514\u2500\u2500 versions.tf             # Provider versions\n\u2502\n\u2514\u2500\u2500 modules/\n    \u2514\u2500\u2500 ec2_minimal/            # Reusable EC2 module\n        \u251c\u2500\u2500 main.tf             # Module logic\n        \u251c\u2500\u2500 variables.tf        # Module inputs\n        \u251c\u2500\u2500 outputs.tf          # Module outputs\n        \u251c\u2500\u2500 versions.tf         # Required providers\n        \u2514\u2500\u2500 tests/\n            \u2514\u2500\u2500 ec2_minimal.tftest.hcl  # Module tests\n</code></pre>"},{"location":"terraform/#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"terraform/#prerequisites","title":"Prerequisites","text":"<pre><code># Install Terraform\nbrew install terraform  # macOS\n# or\nwget https://releases.hashicorp.com/terraform/1.9.5/terraform_1.9.5_linux_amd64.zip\nunzip terraform_1.9.5_linux_amd64.zip\nsudo mv terraform /usr/local/bin/\n\n# Verify installation\nterraform version\n</code></pre>"},{"location":"terraform/#deploy-infrastructure","title":"Deploy Infrastructure","text":"<pre><code>cd terraform/aws-ec2\n\n# Initialize Terraform\nterraform init\n\n# Validate configuration\nterraform validate\n\n# Format code\nterraform fmt -recursive\n\n# Preview changes\nterraform plan\n\n# Apply infrastructure\nterraform apply\n\n# Destroy when done\nterraform destroy\n</code></pre>"},{"location":"terraform/#configuration","title":"\ud83d\udd27 Configuration","text":""},{"location":"terraform/#aws-ec2-module","title":"AWS EC2 Module","text":"<p>Key Features:</p> <ul> <li>IMDSv2 Enforcement: Metadata service hardening</li> <li>EBS Encryption: At-rest encryption for volumes</li> <li>SSM Integration: Remote management without SSH keys</li> <li>Security Groups: Restricted ingress/egress rules</li> <li>User Data: Cloud-init for initial bootstrapping</li> <li>Tags: Comprehensive resource tagging</li> </ul> <p>Example Usage:</p> <pre><code>module \"ec2\" {\n  source = \"./modules/ec2_minimal\"\n\n  instance_name = \"web-server\"\n  instance_type = \"t3.micro\"\n  ami_id        = \"ami-0c55b159cbfafe1f0\"\n\n  vpc_id    = \"vpc-xxxxx\"\n  subnet_id = \"subnet-xxxxx\"\n\n  enable_ssm         = true\n  enable_encryption  = true\n  enable_monitoring  = true\n\n  tags = {\n    Environment = \"production\"\n    ManagedBy   = \"Terraform\"\n  }\n}\n</code></pre>"},{"location":"terraform/#variables","title":"Variables","text":"<p>Edit <code>variables.tf</code> or create <code>terraform.tfvars</code>:</p> <pre><code># AWS Configuration\nregion        = \"us-east-1\"\ninstance_type = \"t3.micro\"\ninstance_name = \"homelab-server\"\n\n# Security\nenable_ssm        = true\nenable_encryption = true\n\n# Networking\nvpc_id    = \"vpc-xxxxx\"\nsubnet_id = \"subnet-xxxxx\"\n\n# Tags\ntags = {\n  Environment = \"dev\"\n  Project     = \"homelab\"\n}\n</code></pre>"},{"location":"terraform/#testing","title":"\ud83e\uddea Testing","text":""},{"location":"terraform/#module-tests","title":"Module Tests","text":"<pre><code>cd terraform/modules/ec2_minimal\n\n# Initialize for testing\nterraform init -backend=false\n\n# Run tests\nterraform test\n\n# Expected output:\n# Success! 3 passed, 0 failed.\n</code></pre>"},{"location":"terraform/#test-coverage","title":"Test Coverage","text":"<ul> <li>\u2705 IMDSv2 enabled</li> <li>\u2705 EBS encryption enabled</li> <li>\u2705 Proper tagging applied</li> <li>\u2705 Security group validation</li> <li>\u2705 SSM IAM role attached</li> </ul>"},{"location":"terraform/#security-features","title":"\ud83d\udd10 Security Features","text":""},{"location":"terraform/#checkov-compliance","title":"Checkov Compliance","text":"<p>All configurations pass Checkov security scanning:</p> <pre><code>checkov -d terraform/\n</code></pre> <p>Implemented Controls:</p> Feature Status Description IMDSv2 Enforced \u2705 Metadata v2 required, prevents SSRF attacks EBS Encrypted \u2705 At-rest encryption for all volumes No Hardcoded Credentials \u2705 Uses AWS provider authentication SSM IAM Role \u2705 Remote access without SSH keys Security Groups \u2705 Restricted ingress rules Resource Tagging \u2705 All resources properly tagged"},{"location":"terraform/#imdsv2-configuration","title":"IMDSv2 Configuration","text":"<pre><code>metadata_options {\n  http_endpoint               = \"enabled\"\n  http_tokens                 = \"required\"\n  http_put_response_hop_limit = 1\n  instance_metadata_tags      = \"enabled\"\n}\n</code></pre>"},{"location":"terraform/#ebs-encryption","title":"EBS Encryption","text":"<pre><code>root_block_device {\n  encrypted   = true\n  volume_size = 20\n  volume_type = \"gp3\"\n\n  delete_on_termination = true\n}\n</code></pre>"},{"location":"terraform/#multi-environment-management","title":"\ud83c\udf0d Multi-Environment Management","text":""},{"location":"terraform/#terraform-workspaces","title":"Terraform Workspaces","text":"<pre><code># Create environments\nterraform workspace new dev\nterraform workspace new staging\nterraform workspace new prod\n\n# Switch environments\nterraform workspace select dev\n\n# List workspaces\nterraform workspace list\n\n# Deploy to specific environment\nterraform apply -var-file=env/dev.tfvars\n</code></pre>"},{"location":"terraform/#environment-specific-variables","title":"Environment-Specific Variables","text":"<pre><code>terraform/\n\u2514\u2500\u2500 aws-ec2/\n    \u251c\u2500\u2500 main.tf\n    \u2514\u2500\u2500 env/\n        \u251c\u2500\u2500 dev.tfvars\n        \u251c\u2500\u2500 staging.tfvars\n        \u2514\u2500\u2500 prod.tfvars\n</code></pre>"},{"location":"terraform/#outputs","title":"\ud83d\udcca Outputs","text":"<p>After successful deployment:</p> <pre><code>terraform output\n\n# Example outputs:\npublic_ip    = \"54.123.45.67\"\ninstance_id  = \"i-0abc123def456789\"\nprivate_ip   = \"10.0.1.50\"\n</code></pre>"},{"location":"terraform/#using-outputs","title":"Using Outputs","text":"<pre><code># Get specific output\nterraform output -raw public_ip\n\n# SSH to instance\nssh ubuntu@$(terraform output -raw public_ip)\n\n# Use in scripts\nINSTANCE_ID=$(terraform output -raw instance_id)\naws ec2 describe-instances --instance-ids $INSTANCE_ID\n</code></pre>"},{"location":"terraform/#cicd-integration","title":"\ud83d\udd04 CI/CD Integration","text":""},{"location":"terraform/#github-actions-workflow","title":"GitHub Actions Workflow","text":"<p>Automated validation on every push:</p> <pre><code>name: Terraform CI\n\non: [push, pull_request]\n\njobs:\n  terraform:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Terraform\n        uses: hashicorp/setup-terraform@v3\n\n      - name: Terraform Format\n        run: terraform fmt -check -recursive\n\n      - name: Terraform Init\n        run: terraform init -backend=false\n\n      - name: Terraform Validate\n        run: terraform validate\n\n      - name: Terraform Test\n        run: terraform test\n\n      - name: Security Scan\n        run: checkov -d terraform/\n</code></pre>"},{"location":"terraform/#jenkins-pipeline","title":"Jenkins Pipeline","text":"<pre><code>stage('Terraform Validation') {\n  steps {\n    container('terraform') {\n      sh '''\n        terraform init -backend=false\n        terraform validate\n        terraform fmt -check\n      '''\n    }\n  }\n}\n\nstage('Terraform Test') {\n  steps {\n    container('terraform') {\n      sh 'terraform test'\n    }\n  }\n}\n</code></pre>"},{"location":"terraform/#integration-with-ansible","title":"\ud83d\udd17 Integration with Ansible","text":""},{"location":"terraform/#cloud-init-bootstrap","title":"Cloud-Init Bootstrap","text":"<p>Terraform provisions instances with cloud-init that triggers Ansible:</p> <pre><code>user_data = &lt;&lt;-EOF\n  #!/bin/bash\n  # Install Ansible\n  apt-add-repository ppa:ansible/ansible -y\n  apt-get update\n  apt-get install -y ansible\n\n  # Run Ansible playbook\n  ansible-pull -U https://github.com/user/ansible-repo\nEOF\n</code></pre>"},{"location":"terraform/#inventory-generation","title":"Inventory Generation","text":"<pre><code># Generate Ansible inventory from Terraform outputs\nterraform output -json | jq -r '.instance_ips.value[]' &gt; ansible/inventory.ini\n</code></pre>"},{"location":"terraform/#integration-with-packer","title":"\ud83d\udd17 Integration with Packer","text":""},{"location":"terraform/#use-custom-ami","title":"Use Custom AMI","text":"<pre><code># Data source to find Packer-built AMI\ndata \"aws_ami\" \"homelab_ubuntu\" {\n  most_recent = true\n  owners      = [\"self\"]\n\n  filter {\n    name   = \"name\"\n    values = [\"homelab-ubuntu-22.04-*\"]\n  }\n}\n\n# Use in EC2 instance\nresource \"aws_instance\" \"server\" {\n  ami = data.aws_ami.homelab_ubuntu.id\n\n  # All security hardening pre-baked!\n  # No user_data provisioning needed\n}\n</code></pre>"},{"location":"terraform/#best-practices-implemented","title":"\ud83d\udcda Best Practices Implemented","text":"<ul> <li>\u2705 Module Reusability: DRY principle with ec2_minimal module</li> <li>\u2705 Version Pinning: Provider versions locked</li> <li>\u2705 State Locking: Prevent concurrent modifications</li> <li>\u2705 Sensitive Data: Using sensitive = true for outputs</li> <li>\u2705 Resource Naming: Consistent naming conventions</li> <li>\u2705 Tagging Strategy: All resources tagged</li> <li>\u2705 Documentation: Inline comments and README</li> <li>\u2705 Testing: Automated tests for modules</li> </ul>"},{"location":"terraform/#skills-demonstrated","title":"\ud83c\udf93 Skills Demonstrated","text":"<ul> <li>\u2705 Terraform HCL: Resource blocks, modules, data sources</li> <li>\u2705 Module Development: Reusable, testable components</li> <li>\u2705 Testing Framework: terraform test for validation</li> <li>\u2705 Security Hardening: IMDSv2, encryption, least privilege</li> <li>\u2705 CI/CD Integration: Automated validation pipelines</li> <li>\u2705 Multi-Environment: Workspace management</li> <li>\u2705 State Management: Backend configuration</li> <li>\u2705 AWS Services: EC2, VPC, IAM, security groups</li> </ul>"},{"location":"terraform/#references","title":"\ud83d\udcd6 References","text":"<ul> <li>Code: <code>terraform/aws-ec2/</code></li> <li>Module: <code>terraform/modules/ec2_minimal/</code></li> <li>Tests: <code>terraform/modules/ec2_minimal/tests/</code></li> <li>Terraform Documentation</li> <li>AWS Provider</li> </ul> <p>Built by Stephon Skipper | GitHub</p>"}]}